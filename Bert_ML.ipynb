{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJwPi6MHmzy2"
   },
   "source": [
    "<h2 style=\"text-align: center\">344.075 KV: Natural Language Processing (WS2024)</h2>\n",
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 3</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Document Classification with PyTorch and BERT</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6Sl7uzjmzy3"
   },
   "source": [
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University (JKU) Linz, and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "\n",
    "**Authors:** Shah Nawaz, Shahed Masoudian<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4nyZdpumzy4"
   },
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-tensorboard\"><li style=\"font-size:large;font-weight:bold\">Bonus Task: Logging and Publishing Experiment Results (2 extra point)</li></a>\n",
    "    <a href=\"#section-taskA\"><li style=\"font-size:large;font-weight:bold\">Task A: Document Classification with PyTorch (25 points)</li></a>\n",
    "    <a href=\"#section-taskB\"><li style=\"font-size:large;font-weight:bold\">Task B: Document Classification with BERT (15 points)</li></a>\n",
    "    \n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFt5RhVOmzy4"
   },
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAUGaV8Hmzy5"
   },
   "source": [
    "### Assignment objective\n",
    "This assignment aims to provide the necessary practices for learning the principles of deep learning programing in NLP using PyTorch. To this end, Task A provides the space for becoming fully familiar with PyTorch programming by implementing a \"simple\" document (sentence) classification model with PyTorch, and Task B extends this classifier with a BERT model. As the assignment requires working with PyTorch and Huggingface Transformers, please familiarize yourself with these libraries using any possible available teaching resources in particular the libraries' documentations. The assignment has in total **40 points**, and also offers **2 extra points** which can cover any missing point.\n",
    "\n",
    "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way!\n",
    "\n",
    "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IR0qtxlmzy6"
   },
   "source": [
    "### Libraries & Dataset\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python`, `PyTorch` and, `transformers`. Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "To conduct the experiments, we use a subset of the `HumSet` dataset [1] (https://blog.thedeep.io/humset/). `HumSet` is created by the DEEP (https://www.thedeep.io) project â€“ an open source platform which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset contains the classes (labels) referring to the humanitarian sectors like agriculture, health, and protection. The dataset contains an overall number of 17,301 data points.\n",
    "\n",
    "Download the dataset from the Moodle page of the course.\n",
    "\n",
    "the provided zip file consists of the following files:\n",
    "- `thedeep.subset.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.label.txt`: Captions of the labels.\n",
    "- `thedeep.ToU.txt`: Terms of use of the dataset.\n",
    "\n",
    "[1] HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response\n",
    "*Selim Fekih, Nicolo' Tamagnone, Benjamin Minixhofer, Ranjan Shrestha, Ximena Contla, Ewan Oglethorpe and Navid Rekabsaz.*\n",
    "In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP), December 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bdrw1Iimzy6"
   },
   "source": [
    "### Submission\n",
    "\n",
    "Each group should submit the following two files:\n",
    "\n",
    "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook.\n",
    "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
    "\n",
    "You do not need to include the data files in the submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMDPTtXemzy7"
   },
   "source": [
    "<a name=\"section-tensorboard\"></a><h2 style=\"color:rgb(0,120,170)\">Bonus Task: Logging and Publishing Experiment Results (2 extra point)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpwv3tmGmzy7"
   },
   "source": [
    "In all experiments of this assignment, use any experiment monitoring tool like [`TensorBoard`](https://www.tensorflow.org/tensorboard), [`wandb`](https://wandb.ai) to log and store all useful information about the training and evaluation of the models. Feel free to log any important aspect in particular the changes in evaluation results on validation, in training loss, and in learning rate.\n",
    "\n",
    "After finalizing all experiments and cleaning any unnecessary experiment, **provide the URL to the results monitoring page below**.\n",
    "\n",
    "For instance if using [`TensorBoard.dev`](https://tensorboard.dev), you can run the following command in the folder of log files: `tensorboard dev upload --name my_exp --logdir path/to/output_dir`, and take the provided URL to the TensorBoard's console.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDoeL80Lmzy8"
   },
   "source": [
    "**URL :** *EDIT!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gnCwi2umzy8"
   },
   "source": [
    "<a name=\"section-taskA\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Document Classification with PyTorch (25 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ9KSEgtmzy8"
   },
   "source": [
    "The aim of this task is identical to the one of Assignment 2 - Task B, namely to design a document classification model that exploits pre-trained word embeddings. It is of course allowed to use the preprocessed text, the dictionary, or any other relevant code or processings, done in the previous assignments.\n",
    "\n",
    "In this task, you implement a document classification model using PyTorch, which given a document/sentence (consisting of a set of words) predicts the corresponding class. Before getting started with coding, have a look at the <a href=\"#section-tensorboard\">optional task</a>, as you may want to already include `Tensorboard` in the code. The implementation of the classifier should cover the points below.\n",
    "\n",
    "**Preprocessing and dictionary (1 point):** Following previous assignments, load the train, validation, and test datasets, apply necessary preprocessing steps, and create a dictionary of words.\n",
    "\n",
    "**Data batching (4 points):** Using the dictionary, create batches for any given dataset (train/validation/test). Each batch is a two-dimensional matrix of *batch-size* to *max-document-length*, containing the IDs of the words in the corresponding documents. *Batch-size* and *max-document-length* are two hyper-parameters and can be set to any appropriate values (*Batch-size* must be higher than 1 and *max-document-length* at least 50 words). If a document has more than *max-document-length* words, only the first *max-document-length* words should be kept.\n",
    "\n",
    "**Word embedding lookup (2 point):** Using `torch.nn.Embedding`, create a lookup for the embeddings of all the words in the dictionary. The lookup is in fact a matrix, which maps the ID of each word to the corresponding word vector. Similar to Assignment 2, use the pre-trained vectors of a word embedding model (like word2vec or GloVe) to initialize the word embeddings of the lookup. Keep in mind that the embeddings of the words in the lookup should be matched with the correct vector in the pretrained word embedding. If the vector of a word in the lookup does not exist in the pretrained word embeddings, the corresponding vector should be initialized randomly.\n",
    "\n",
    "**Model definition (3 points):** Define the class `ClassificationAverageModel` as a PyTorch model. In the initialization procedure, the model receives the word embedding lookup, and includes it in the model as model's parameters. These embeddings parameters should be trainable, meaning that the word vectors get updated during model training. Feel free to add any other parameters to the model, which might be necessary for accomplishing the functionalities explained in the following.\n",
    "\n",
    "**Forward function (5 points):** The forward function of the model receives a batch of data, and first fetches the corresponding embeddings of the word IDs in the batch using the lookup. Similar to Assignment 2, the embedding of a document is created by calculating the *element-wise mean* of the embeddings of the document's words. Formally, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
    "\n",
    "<center><div>$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$</div></center>\n",
    "\n",
    "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document. An important point in the implementation of this formula is that the documents in the batch might have different lengths and therefore each document should be divided by its corresponding $|d|$. Finally, this document embedding is utilized to predict the probability of the output classes, done by applying a linear transformation from the embeddings size to the number of classes, followed by Softmax. The linear transformation also belongs to the model's parameters and will be learned in training.\n",
    "\n",
    "**Loss Function and optimization (2 point):** The loss between the predicted and the actual classes is calculated using Negative Log Likelihood or Cross Entropy. Update the model's parameters using any appropriate optimization mechanism such as Adam.\n",
    "\n",
    "**Early Stopping (2 points):** After each epoch, evaluate the model on the *validation set* using accuracy. If the evaluation result (accuracy) improves, save the model as the best performing one so far. If the results are not improving after a certain number of evaluation rounds (set as another hyper-parameter) or if training reaches a certain number of epochs, terminate the training procedure.\n",
    "\n",
    "**Test Set Evaluation (1 point):** After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set.\n",
    "\n",
    "**Reporting (1 point):** During loading and processing the collection, provide sufficient information and examples about the data and the applied processing steps. Report the results of the best performing model on the validation and test set in a table.\n",
    "\n",
    "**Overall functionality of the training procedure (4 point).**\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfbI7BxD4gjk",
    "outputId": "b9fb8883-d054-4fd8-91d3-60ecbf3b9417"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLWtJgdYmzy8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5bb84947-adbb-451e-cb36-f461aec562c1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Xq5YlKUI28c"
   },
   "source": [
    "# Preprocessing and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO3Gqhc4m5u5"
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(\"/content/drive/My Drive/NLP/thedeep.subset.train.txt\", delimiter=\",\", names=['sentence_id', 'text', 'label'])\n",
    "valData = pd.read_csv(\"/content/drive/My Drive/NLP/thedeep.subset.validation.txt\", delimiter=\",\", names=['sentence_id', 'text', 'label'])\n",
    "testData = pd.read_csv(\"/content/drive/My Drive/NLP/thedeep.subset.test.txt\", delimiter=\",\", names=['sentence_id', 'text', 'label'])\n",
    "label_mapping = {}\n",
    "with open(\"/content/drive/My Drive/NLP/thedeep.labels.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) >= 2:\n",
    "            label_id = parts[0]\n",
    "            label_name = ','.join(parts[1:])  # Handle label names with commas\n",
    "            label_mapping[label_id] = label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WypPU1S3m5qL",
    "outputId": "7d1d2cb7-de8a-400b-8589-ca441941a0d6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sentence_id                                               text  label\n",
       "0         5446  In addition to the immediate life-saving inter...      9\n",
       "1         8812  There are approximately 2.6 million people cla...      3\n",
       "2        16709  While aid imports have held up recently, comme...      5\n",
       "3         3526  Heavy rainfalls as well as onrush of water fro...      0\n",
       "4         4928  Based on field reports 9 , the main production...      3"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-6156a121-5ddb-4fdb-ae01-ae1da71ecc89\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5446</td>\n",
       "      <td>In addition to the immediate life-saving inter...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8812</td>\n",
       "      <td>There are approximately 2.6 million people cla...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16709</td>\n",
       "      <td>While aid imports have held up recently, comme...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3526</td>\n",
       "      <td>Heavy rainfalls as well as onrush of water fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4928</td>\n",
       "      <td>Based on field reports 9 , the main production...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6156a121-5ddb-4fdb-ae01-ae1da71ecc89')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6156a121-5ddb-4fdb-ae01-ae1da71ecc89 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6156a121-5ddb-4fdb-ae01-ae1da71ecc89');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7222fb17-43a5-4be2-8a0f-c32009a9f3c0\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7222fb17-43a5-4be2-8a0f-c32009a9f3c0')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7222fb17-43a5-4be2-8a0f-c32009a9f3c0 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "trainData",
       "summary": "{\n  \"name\": \"trainData\",\n  \"rows\": 12110,\n  \"fields\": [\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5018,\n        \"min\": 1,\n        \"max\": 17300,\n        \"num_unique_values\": 12110,\n        \"samples\": [\n          8233,\n          3555,\n          17283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12072,\n        \"samples\": [\n          \"Kenyan military has announced it will bomb Boni forest in Kenya\\u2019s coastal county of Lamu to annihilate Al-Shabaab militants who have launched several attacks on civilians.\",\n          \" Nutrition  The SMART survey results are available and confirm that the nutritional situation in the Diffa region is serious. More particularly, the survey findings show that nutrition indicators are critical in Main\\u00e9 Soroa having a global acute malnutrition (GAM) rate of 16 percent, with a high prevalence of morbidity (fever and diarrhea). Results found an improvement in the level of certain Infant and Young Child Feeding (IYCF) indicators.  On 24 and 25 January, WFP, the Directorate of Nutrition and the Diffa Regional Directorate of Public Health organized a workshop to report key results obtained from surveys conducted in the Diffa region between July and December 2017 (the SMART survey, the survey on the coverage of malnutrition support and the assessment of Emergency Food and Nutrition Security). This event brought together all nutrition and food security actors working in the region, with the objective of facilitating the appropriation of the surveys\\u2019 key results to be retained and to plan short and mediumterm activities which resulted in the development of a road map for improving nutrition security. A serious shortfall in the nutrition pipeline is forcing WFP to interrupt all moderate acute malnutrition (MAM) treatment activities and concentrate the scarce resources in the Diffa region only.\",\n          \"In Somalia, 1.8 million people had been reached with safe water, and in Nigeria over 2.6 million people will be reached with a basic supply of clean water this year, UNICEF said.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          7,\n          11,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmOcL2t3m5nK"
   },
   "outputs": [],
   "source": [
    "# drop ID sentence\n",
    "trainData = trainData.drop(['sentence_id'], axis=1)\n",
    "valData = valData.drop(['sentence_id'], axis=1)\n",
    "testData = testData.drop(['sentence_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NnN5AXXvm5kT",
    "outputId": "1606e8ad-3f37-4e62-fd4d-eec958eafce1"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  In addition to the immediate life-saving inter...      9\n",
       "1  There are approximately 2.6 million people cla...      3\n",
       "2  While aid imports have held up recently, comme...      5\n",
       "3  Heavy rainfalls as well as onrush of water fro...      0\n",
       "4  Based on field reports 9 , the main production...      3"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-6d8fe7d1-aee3-4873-a7a7-fbb7af01930d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In addition to the immediate life-saving inter...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are approximately 2.6 million people cla...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While aid imports have held up recently, comme...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy rainfalls as well as onrush of water fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on field reports 9 , the main production...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d8fe7d1-aee3-4873-a7a7-fbb7af01930d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6d8fe7d1-aee3-4873-a7a7-fbb7af01930d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6d8fe7d1-aee3-4873-a7a7-fbb7af01930d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-4427759e-61dc-4ebf-b4ee-878a5fa032b6\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4427759e-61dc-4ebf-b4ee-878a5fa032b6')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-4427759e-61dc-4ebf-b4ee-878a5fa032b6 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "trainData",
       "summary": "{\n  \"name\": \"trainData\",\n  \"rows\": 12110,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12072,\n        \"samples\": [\n          \"Kenyan military has announced it will bomb Boni forest in Kenya\\u2019s coastal county of Lamu to annihilate Al-Shabaab militants who have launched several attacks on civilians.\",\n          \" Nutrition  The SMART survey results are available and confirm that the nutritional situation in the Diffa region is serious. More particularly, the survey findings show that nutrition indicators are critical in Main\\u00e9 Soroa having a global acute malnutrition (GAM) rate of 16 percent, with a high prevalence of morbidity (fever and diarrhea). Results found an improvement in the level of certain Infant and Young Child Feeding (IYCF) indicators.  On 24 and 25 January, WFP, the Directorate of Nutrition and the Diffa Regional Directorate of Public Health organized a workshop to report key results obtained from surveys conducted in the Diffa region between July and December 2017 (the SMART survey, the survey on the coverage of malnutrition support and the assessment of Emergency Food and Nutrition Security). This event brought together all nutrition and food security actors working in the region, with the objective of facilitating the appropriation of the surveys\\u2019 key results to be retained and to plan short and mediumterm activities which resulted in the development of a road map for improving nutrition security. A serious shortfall in the nutrition pipeline is forcing WFP to interrupt all moderate acute malnutrition (MAM) treatment activities and concentrate the scarce resources in the Diffa region only.\",\n          \"In Somalia, 1.8 million people had been reached with safe water, and in Nigeria over 2.6 million people will be reached with a basic supply of clean water this year, UNICEF said.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          7,\n          11,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# print the new Head of train data to see results\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNrrDN2Ym5hZ"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def pp_text(text):\n",
    "    #lower casing, removing puncation and numbers\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    #Tokenize and remove stopwords\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "    #stemming\n",
    "    stemTokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return stemTokens\n",
    "\n",
    "#apply preprocessing\n",
    "trainData['clean_text'] = trainData['text'].apply(pp_text)\n",
    "valData['clean_text'] = valData['text'].apply(pp_text)\n",
    "testData['clean_text'] = testData['text'].apply(pp_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3URViT9vINc",
    "outputId": "99c8917d-cec3-471d-be9d-d0e5dde25ffa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The initial sentence was= Overall 30% decrease in MAM Children admissions from 12,879 in April 2016 to 9,047 in April 2017\n",
      "The cleaned sentence is= ['overal', ' ', 'decreas', 'mam', 'children', 'admiss', ' ', 'april', ' ', ' ', 'april']\n"
     ]
    }
   ],
   "source": [
    "print(f'The initial sentence was=', testData['text'][0])\n",
    "print(f'The cleaned sentence is=', testData['clean_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeUf284cvIK8"
   },
   "outputs": [],
   "source": [
    "def clean(tokens):\n",
    "    return [token for token in tokens if token.strip()]\n",
    "\n",
    "trainData['clean_text'] = trainData['clean_text'].apply(clean)\n",
    "valData['clean_text'] = valData['clean_text'].apply(clean)\n",
    "testData['clean_text'] = testData['clean_text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fkh8V1bfvIId",
    "outputId": "e6daded1-7ae4-4f83-979b-bf135c47ed26"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample cleaned data from trainData:\n",
      "0    [addit, immedi, lifesav, intervent, unicef, ta...\n",
      "1    [approxim, million, peopl, classifi, phase, mi...\n",
      "Name: clean_text, dtype: object\n",
      "\n",
      "Sample cleaned data from valData:\n",
      "0    [veteran, threw, roadblock, main, northbound, ...\n",
      "1    [water, depart, complain, lack, skill, worker,...\n",
      "Name: clean_text, dtype: object\n",
      "\n",
      "Sample cleaned data from testData:\n",
      "0    [overal, decreas, mam, children, admiss, april...\n",
      "1    [fear, ebola, led, attack, health, worker, apr...\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Now lets see if that worked out\n",
    "print(\"Sample cleaned data from trainData:\")\n",
    "print(trainData['clean_text'].head(2))\n",
    "print(\"\\nSample cleaned data from valData:\")\n",
    "print(valData['clean_text'].head(2))\n",
    "print(\"\\nSample cleaned data from testData:\")\n",
    "print(testData['clean_text'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ha4azoWvvIF1",
    "outputId": "55f2dab6-73de-4547-c594-799ddf07cf47"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial vocabulary size: 23270\n",
      "Top 10 most frequent tokens: [('case', 5594), ('report', 5113), ('food', 4262), ('peopl', 3881), ('area', 3524), ('children', 2953), ('water', 2557), ('health', 2477), ('increas', 2258), ('includ', 2220)]\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(int)\n",
    "for tokens in trainData['clean_text']:\n",
    "    for word in tokens:\n",
    "        vocab[word] += 1\n",
    "\n",
    "#Check the initial vocabulary size and display some sample tokens\n",
    "initial_vocab_size = len(vocab)\n",
    "print(f\"Initial vocabulary size: {initial_vocab_size}\")\n",
    "print(\"Top 10 most frequent tokens:\", sorted(vocab.items(), key=lambda x: x[1], reverse=True)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ik_uFet6vH_-",
    "outputId": "0a131b46-f6c0-431a-b34d-2927b9943a08"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample sentence is: In 2014, fear of Ebola also led to attacks on health workers. In April 2014, an angry crowd attacked an Ebola treatment center in Macenta, 425 kilometers southeast of Guineaâ€™s capital, Conakry, run by Doctors Without Borders (Medecins Sans Frontieres or MSF), which it accused of bringing Ebola to the city. In August 2014, people in Nâ€™ZÃ©rÃ©korÃ©, Guineaâ€™s second largest city, protested spraying a market with disinfectant that they believed was infected with the Ebola virus and rioted, injuring over 50 people, including security forces. Law enforcement agencies in Congo should ensure that they can quickly, adequately, and appropriately respond if similar attacks occur.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The tokens of the sentence are: ['fear', 'ebola', 'led', 'attack', 'health', 'worker', 'april', 'angri', 'crowd', 'attack', 'ebola', 'treatment', 'center', 'macenta', 'kilomet', 'southeast', 'guinea', 'capit', 'conakri', 'run', 'doctor', 'border', 'medecin', 'san', 'frontier', 'msf', 'accus', 'bring', 'ebola', 'citi', 'august', 'peopl', 'nzÃ©rÃ©korÃ©', 'guinea', 'second', 'largest', 'citi', 'protest', 'spray', 'market', 'disinfect', 'believ', 'infect', 'ebola', 'viru', 'riot', 'injur', 'peopl', 'includ', 'secur', 'forc', 'law', 'enforc', 'agenc', 'congo', 'ensur', 'quickli', 'adequ', 'appropri', 'respond', 'similar', 'attack', 'occur']\n"
     ]
    }
   ],
   "source": [
    "sample_index = 1\n",
    "print(f\"Sample sentence is: {testData['text'][sample_index]}\")\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "#print the tokens of the sentence after preprocessing, vocabulary reduction, and OOV handling\n",
    "print(f\"The tokens of the sentence are: {testData['clean_text'][sample_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7FbCf1svH5N",
    "outputId": "d1007e85-d414-4db2-d097-e8041f128713"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial vocabulary size: 23270\n",
      "Reduced vocabulary size after applying frequency threshold: 11198\n"
     ]
    }
   ],
   "source": [
    "#frequency threshold to filter tokens\n",
    "freqThreshold = 1\n",
    "vocabReduced = {token for token, freq in vocab.items() if freq > freqThreshold}\n",
    "\n",
    "initial_vocab_size = len(vocab)\n",
    "reduced_vocab_size = len(vocabReduced)\n",
    "print(f\"Initial vocabulary size: {initial_vocab_size}\")\n",
    "print(f\"Reduced vocabulary size after applying frequency threshold: {reduced_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zz6XJJQDm5Za",
    "outputId": "1614c6b2-7cd3-4445-9fd8-a3b1d0669671"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original sentence: In 2014, fear of Ebola also led to attacks on health workers. In April 2014, an angry crowd attacked an Ebola treatment center in Macenta, 425 kilometers southeast of Guineaâ€™s capital, Conakry, run by Doctors Without Borders (Medecins Sans Frontieres or MSF), which it accused of bringing Ebola to the city. In August 2014, people in Nâ€™ZÃ©rÃ©korÃ©, Guineaâ€™s second largest city, protested spraying a market with disinfectant that they believed was infected with the Ebola virus and rioted, injuring over 50 people, including security forces. Law enforcement agencies in Congo should ensure that they can quickly, adequately, and appropriately respond if similar attacks occur.\n",
      "Tokens after preprocessing and OOV handling: ['fear', 'ebola', 'led', 'attack', 'health', 'worker', 'april', 'angri', 'crowd', 'attack', 'ebola', 'treatment', 'center', '<OOV>', 'kilomet', 'southeast', 'guinea', 'capit', 'conakri', 'run', 'doctor', 'border', 'medecin', 'san', 'frontier', 'msf', 'accus', 'bring', 'ebola', 'citi', 'august', 'peopl', '<OOV>', 'guinea', 'second', 'largest', 'citi', 'protest', 'spray', 'market', 'disinfect', 'believ', 'infect', 'ebola', 'viru', 'riot', 'injur', 'peopl', 'includ', 'secur', 'forc', 'law', 'enforc', 'agenc', 'congo', 'ensur', 'quickli', 'adequ', 'appropri', 'respond', 'similar', 'attack', 'occur']\n"
     ]
    }
   ],
   "source": [
    "#function handle OOV by replacing them with OOV\n",
    "def replace_oov(tokens, vocab):\n",
    "    return [token if token in vocab else \"<OOV>\" for token in tokens]\n",
    "\n",
    "trainData['clean_text'] = trainData['clean_text'].apply(lambda tokens: replace_oov(tokens, vocabReduced))\n",
    "valData['clean_text'] = valData['clean_text'].apply(lambda tokens: replace_oov(tokens, vocabReduced))\n",
    "testData['clean_text'] = testData['clean_text'].apply(lambda tokens: replace_oov(tokens, vocabReduced))\n",
    "\n",
    "sample_index = 1\n",
    "print(f\"Original sentence: {testData['text'][sample_index]}\")\n",
    "print(f\"Tokens after preprocessing and OOV handling: {testData['clean_text'][sample_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHw774xOxJdp"
   },
   "outputs": [],
   "source": [
    "# Function to calculate TF-IDF weights\n",
    "def calculate_tfidf(corpus, vocab):\n",
    "    doc_count = len(corpus)\n",
    "    tfidf_vectors = []\n",
    "    idf = {}\n",
    "\n",
    "    # Compute IDF for each term in vocab\n",
    "    for token in vocab:\n",
    "        doc_freq = sum(1 for doc in corpus if token in doc)\n",
    "        idf[token] = np.log((doc_count + 1) / (doc_freq + 1)) + 1\n",
    "\n",
    "    # Compute TF-IDF for each document\n",
    "    for tokens in corpus:\n",
    "        tfidf_vector = np.zeros(len(vocab))\n",
    "        term_counts = defaultdict(int)\n",
    "\n",
    "        # Term frequency\n",
    "        for token in tokens:\n",
    "            term_counts[token] += 1\n",
    "\n",
    "        for idx, token in enumerate(vocab):\n",
    "            tf = term_counts[token] / len(tokens)\n",
    "            tfidf_vector[idx] = tf * idf[token] if token in term_counts else 0\n",
    "\n",
    "        tfidf_vectors.append(tfidf_vector)\n",
    "\n",
    "    return np.array(tfidf_vectors)\n",
    "\n",
    "# Generate TF-IDF vectors\n",
    "tfidf_train = calculate_tfidf(trainData['clean_text'], vocabReduced)\n",
    "tfidf_val = calculate_tfidf(valData['clean_text'], vocabReduced)\n",
    "tfidf_test = calculate_tfidf(testData['clean_text'], vocabReduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCDg1I2hxJaD"
   },
   "outputs": [],
   "source": [
    "# Function to calculate BM25 weights\n",
    "def calculate_bm25(corpus, vocab, k=1.5, b=0.75):\n",
    "    doc_count = len(corpus)\n",
    "    avg_doc_len = np.mean([len(doc) for doc in corpus])\n",
    "    bm25_vectors = []\n",
    "    idf = {}\n",
    "\n",
    "    # Compute IDF for each term\n",
    "    for token in vocab:\n",
    "        doc_freq = sum(1 for doc in corpus if token in doc)\n",
    "        idf[token] = np.log((doc_count - doc_freq + 0.5) / (doc_freq + 0.5) + 1)\n",
    "\n",
    "    # Compute BM25 scores\n",
    "    for tokens in corpus:\n",
    "        bm25_vector = np.zeros(len(vocab))\n",
    "        term_counts = defaultdict(int)\n",
    "\n",
    "        for token in tokens:\n",
    "            term_counts[token] += 1\n",
    "\n",
    "        for idx, token in enumerate(vocab):\n",
    "            tf = term_counts[token]\n",
    "            doc_len = len(tokens)\n",
    "            bm25_score = idf[token] * ((tf * (k + 1)) / (tf + k * (1 - b + b * (doc_len / avg_doc_len))))\n",
    "            bm25_vector[idx] = bm25_score if token in term_counts else 0\n",
    "\n",
    "        bm25_vectors.append(bm25_vector)\n",
    "\n",
    "    return np.array(bm25_vectors)\n",
    "\n",
    "# Generate BM25 vectors\n",
    "bm25_train = calculate_bm25(trainData['clean_text'], vocabReduced)\n",
    "bm25_val = calculate_bm25(valData['clean_text'], vocabReduced)\n",
    "bm25_test = calculate_bm25(testData['clean_text'], vocabReduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPMTeD94xJLt",
    "outputId": "d6ce50de-256b-4672-87f5-b8fcc7c4f266"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sparsity rate of TF-IDF vectors for train set: 99.74%\n",
      "Sparsity rate of TF-IDF vectors for validation set: 99.74%\n",
      "Sparsity rate of TF-IDF vectors for test set: 99.74%\n",
      "Sparsity rate of BM25 vectors for train set: 99.74%\n",
      "Sparsity rate of BM25 vectors for validation set: 99.74%\n",
      "Sparsity rate of BM25 vectors for test set: 99.74%\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate sparsity rate\n",
    "def calculate_sparsity(vectors):\n",
    "    total_elements = vectors.size\n",
    "    zero_elements = np.count_nonzero(vectors == 0)\n",
    "    sparsity_rate = (zero_elements / total_elements) * 100\n",
    "    return sparsity_rate\n",
    "\n",
    "# Calculate and print sparsity rates\n",
    "sparsity_tfidf_train = calculate_sparsity(tfidf_train)\n",
    "sparsity_tfidf_val = calculate_sparsity(tfidf_val)\n",
    "sparsity_tfidf_test = calculate_sparsity(tfidf_test)\n",
    "\n",
    "sparsity_bm25_train = calculate_sparsity(bm25_train)\n",
    "sparsity_bm25_val = calculate_sparsity(bm25_val)\n",
    "sparsity_bm25_test = calculate_sparsity(bm25_test)\n",
    "\n",
    "print(f\"Sparsity rate of TF-IDF vectors for train set: {sparsity_tfidf_train:.2f}%\")\n",
    "print(f\"Sparsity rate of TF-IDF vectors for validation set: {sparsity_tfidf_val:.2f}%\")\n",
    "print(f\"Sparsity rate of TF-IDF vectors for test set: {sparsity_tfidf_test:.2f}%\")\n",
    "\n",
    "print(f\"Sparsity rate of BM25 vectors for train set: {sparsity_bm25_train:.2f}%\")\n",
    "print(f\"Sparsity rate of BM25 vectors for validation set: {sparsity_bm25_val:.2f}%\")\n",
    "print(f\"Sparsity rate of BM25 vectors for test set: {sparsity_bm25_test:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC6eJf_79afj"
   },
   "source": [
    "# Data batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHx7w8-n2TIS",
    "outputId": "50b1c122-efc0-49cd-baad-3643161e480c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch 1\n",
      "Word IDs: tensor([[ 7765,  8113,  1358, 10060,  7707,  8339,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 5100,  8243,  1058,  6607,  1606,   717,  4052,  3001,  7707,  2913,\n",
      "          7197,  3001, 10023,  3963,  6607,  4418,  8707, 10732,  5104,  6962,\n",
      "          6418,  7023,  6013,  5196, 11038,  9831,   376,  8860,  1606,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 5889,  7898,   853,  9232,   853,  6150,  6935,  8860,  4229,  8112,\n",
      "          9030,  8747,  9741,  8915,  8544,   119,  8747,  9352,  8001,  5428,\n",
      "         10794,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [10726,  9956,  9079,  2772,  2252, 10685,  3082,  1095,  8003,  9960,\n",
      "          1959, 10726,  9956,  7040,  7560,  4615,  7780,  6075,  7473,  3345,\n",
      "          8689,  8237,  7780,  2389,  6953,  7296,  9079,  9156,  3003,   816,\n",
      "          2257, 10889,  7388,  6062,  6280,  8000,  3658,  8003,  6184,  3004,\n",
      "          9079,  6958,  3022,   559,  7395,  9569, 10726,  9956,  7040,  9069]])\n",
      "Labels: tensor([3, 1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, documents, labels, dictionary, max_document_length):\n",
    "        \"\"\"\n",
    "        :param documents: List of preprocessed documents (list of tokens).\n",
    "        :param labels: List of corresponding labels.\n",
    "        :param dictionary: Dictionary mapping words to IDs.\n",
    "        :param max_document_length: Maximum number of tokens per document.\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.labels = labels\n",
    "        self.dictionary = dictionary\n",
    "        self.max_document_length = max_document_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        document = self.documents[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert words to IDs, handle OOV and padding\n",
    "        word_ids = [self.dictionary.get(word, self.dictionary[\"<OOV>\"]) for word in document]\n",
    "        word_ids = word_ids[:self.max_document_length]\n",
    "\n",
    "        padding = [self.dictionary[\"<PAD>\"]] * (self.max_document_length - len(word_ids))\n",
    "        word_ids.extend(padding)\n",
    "\n",
    "        return torch.tensor(word_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "def create_batches(documents, labels, dictionary, batch_size, max_document_length):\n",
    "    \"\"\"\n",
    "    Creates batches using the DocumentDataset.\n",
    "\n",
    "    :param documents: List of preprocessed documents (list of tokens).\n",
    "    :param labels: List of labels corresponding to the documents.\n",
    "    :param dictionary: Dictionary mapping words to IDs.\n",
    "    :param batch_size: Size of each batch.\n",
    "    :param max_document_length: Maximum length of a document.\n",
    "    :return: DataLoader\n",
    "    \"\"\"\n",
    "    dataset = DocumentDataset(documents, labels, dictionary, max_document_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generating dictionary from the reduced vocabulary\n",
    "    dictionary = {word: idx for idx, word in enumerate(vocabReduced, start=2)}\n",
    "    dictionary[\"<PAD>\"] = 0  # Padding token\n",
    "    dictionary[\"<OOV>\"] = 1  # Out-of-vocabulary token\n",
    "\n",
    "    # Preprocessed dataset\n",
    "    train_documents = trainData['clean_text'].tolist()  # List of tokenized documents\n",
    "    train_labels = trainData['label'].tolist()  # Corresponding labels\n",
    "\n",
    "    # Hyperparameters\n",
    "    batch_size = 4\n",
    "    max_document_length = 50\n",
    "\n",
    "    # Creating batches\n",
    "    train_loader = create_batches(train_documents, train_labels, dictionary, batch_size, max_document_length)\n",
    "\n",
    "    # Displaying batches\n",
    "    for batch_idx, (word_ids, batch_labels) in enumerate(train_loader):\n",
    "        print(f\"Batch {batch_idx + 1}\")\n",
    "        print(\"Word IDs:\", word_ids)\n",
    "        print(\"Labels:\", batch_labels)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGK43zgA9ZdC"
   },
   "source": [
    "# Word embedding lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjtPe00fJ1zq",
    "outputId": "d41930e1-29d8-44be-bdeb-96e343fc6682"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding matrix shape: torch.Size([11200, 100])\n",
      "Example embedding for '<PAD>': tensor([ 0.0260, -0.0175, -0.0525, -0.0034,  0.0345, -0.0733,  0.0166, -0.0394,\n",
      "         0.0415, -0.0380,  0.0474, -0.0601, -0.0004, -0.0283,  0.0757,  0.0986,\n",
      "         0.0325, -0.0703,  0.0127,  0.0423, -0.0759,  0.0078, -0.0315, -0.0555,\n",
      "         0.0590,  0.0349,  0.0849,  0.0690, -0.0102,  0.0831, -0.0291, -0.0753,\n",
      "        -0.0137, -0.0967,  0.0162,  0.0838, -0.0372, -0.0860,  0.0200,  0.0760,\n",
      "         0.0484, -0.0427, -0.0137,  0.0273, -0.0182,  0.0892, -0.0260, -0.0651,\n",
      "         0.0640, -0.0945,  0.0050,  0.0211,  0.0791,  0.0742, -0.0407, -0.0880,\n",
      "         0.0984,  0.0990,  0.0535, -0.0410,  0.0071, -0.0625, -0.0579, -0.0229,\n",
      "        -0.0893,  0.0145, -0.0042,  0.0665,  0.0478, -0.0670, -0.0222,  0.0281,\n",
      "         0.0524, -0.0144, -0.0255, -0.0423, -0.0866,  0.0827,  0.0460,  0.0370,\n",
      "         0.0871, -0.0373, -0.0645, -0.0210,  0.0082, -0.0730,  0.0392,  0.0730,\n",
      "        -0.0180, -0.0475,  0.0941,  0.0876,  0.0768,  0.0885, -0.0002,  0.0634,\n",
      "         0.0150, -0.0611,  0.0803,  0.0094])\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_embeddings(embedding_path, embedding_dim):\n",
    "    \"\"\"\n",
    "    Load pre-trained word embeddings from a file.\n",
    "\n",
    "    :param embedding_path: Path to the pre-trained embeddings file.\n",
    "    :param embedding_dim: Dimensionality of the embeddings.\n",
    "    :return: A dictionary mapping words to their embedding vectors.\n",
    "    \"\"\"\n",
    "    embeddings_index = {}\n",
    "    with open(embedding_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "def create_embedding_matrix(dictionary, embeddings_index, embedding_dim):\n",
    "    \"\"\"\n",
    "    Create an embedding matrix where each row corresponds to a word ID in the dictionary.\n",
    "\n",
    "    :param dictionary: Dictionary mapping words to IDs.\n",
    "    :param embeddings_index: Pre-trained word embeddings.\n",
    "    :param embedding_dim: Dimensionality of the embeddings.\n",
    "    :return: A PyTorch embedding layer.\n",
    "    \"\"\"\n",
    "    vocab_size = len(dictionary)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, idx in dictionary.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[idx] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.uniform(-0.1, 0.1, embedding_dim)\n",
    "\n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    embedding_path = \"/content/drive/My Drive/NLP/glove.6B.100d.txt\"\n",
    "    embedding_dim = 100\n",
    "\n",
    "    # Loading pre-trained embeddings\n",
    "    embeddings_index = load_pretrained_embeddings(embedding_path, embedding_dim)\n",
    "\n",
    "    # Generating the embedding matrix\n",
    "    embedding_matrix = create_embedding_matrix(dictionary, embeddings_index, embedding_dim)\n",
    "\n",
    "    # Creating PyTorch embedding layer\n",
    "    embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "\n",
    "    print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n",
    "    print(f\"Example embedding for '<PAD>': {embedding_matrix[dictionary['<PAD>']]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FK9JrnZg9uyC"
   },
   "source": [
    "# Model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Whim7CD39uRy",
    "outputId": "50cefab3-7027-4365-a7bc-a1a186677e71"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logits shape: torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "class ClassificationAverageModel(nn.Module):\n",
    "    def __init__(self, embedding_layer, embedding_dim, num_classes):\n",
    "        \"\"\"\n",
    "        :param embedding_layer: Pre-trained word embedding lookup (nn.Embedding).\n",
    "        :param embedding_dim: Dimensionality of word embeddings.\n",
    "        :param num_classes: Number of output classes for classification.\n",
    "        \"\"\"\n",
    "        super(ClassificationAverageModel, self).__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Defining a fully connected layer\n",
    "        self.fc = nn.Linear(self.embedding_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        :param input_ids: Input tensor of word IDs (batch_size x max_document_length).\n",
    "        :return: Logits for each class (batch_size x num_classes).\n",
    "        \"\"\"\n",
    "        # Get embeddings for input word IDs\n",
    "        embeddings = self.embedding(input_ids)  # (batch_size x max_document_length x embedding_dim)\n",
    "\n",
    "        # Mean pooling: Average over the max_document_length dimension\n",
    "        pooled_embeddings = embeddings.mean(dim=1)  # (batch_size x embedding_dim)\n",
    "\n",
    "        # Pass the pooled embeddings through the fully connected layer\n",
    "        logits = self.fc(pooled_embeddings)  # (batch_size x num_classes)\n",
    "\n",
    "        return logits\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_classes = 12\n",
    "    embedding_dim = 100\n",
    "    model = ClassificationAverageModel(embedding_layer, embedding_dim, num_classes)\n",
    "    batch_size = 4\n",
    "    max_document_length = 50\n",
    "    input_ids = torch.randint(0, len(dictionary), (batch_size, max_document_length))\n",
    "    logits = model(input_ids)\n",
    "    print(f\"Logits shape: {logits.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59C4I52H_DAi"
   },
   "source": [
    "# Forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEc5QUCL9uOz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "adc72fa5-3643-4bcf-cf0e-65db7b85d5b5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Probabilities shape: torch.Size([4, 12])\n",
      "Probabilities: tensor([[0.0747, 0.0852, 0.0834, 0.0798, 0.0796, 0.0843, 0.0786, 0.1057, 0.0753,\n",
      "         0.0833, 0.0792, 0.0908],\n",
      "        [0.0791, 0.0903, 0.0838, 0.0757, 0.0783, 0.0877, 0.0829, 0.0899, 0.0742,\n",
      "         0.0867, 0.0770, 0.0944],\n",
      "        [0.0782, 0.0903, 0.0850, 0.0831, 0.0782, 0.0827, 0.0804, 0.0916, 0.0763,\n",
      "         0.0811, 0.0776, 0.0956],\n",
      "        [0.0758, 0.0833, 0.0858, 0.0786, 0.0786, 0.0882, 0.0830, 0.0937, 0.0754,\n",
      "         0.0851, 0.0830, 0.0895]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ClassificationAverageModel(nn.Module):\n",
    "    def __init__(self, embedding_layer, embedding_dim, num_classes):\n",
    "        \"\"\"\n",
    "        :param embedding_layer: Pre-trained word embedding lookup (nn.Embedding).\n",
    "        :param embedding_dim: Dimensionality of word embeddings.\n",
    "        :param num_classes: Number of output classes for classification.\n",
    "        \"\"\"\n",
    "        super(ClassificationAverageModel, self).__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Linear(self.embedding_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        :param input_ids: Input tensor of word IDs (batch_size x max_document_length).\n",
    "        :return: Probabilities for each class (batch_size x num_classes).\n",
    "        \"\"\"\n",
    "        # Getting embeddings for input word IDs\n",
    "        embeddings = self.embedding(input_ids)  # (batch_size x max_document_length x embedding_dim)\n",
    "\n",
    "        # Creating a mask for padding (PAD = 0)\n",
    "        mask = (input_ids != 0).float()  # (batch_size x max_document_length)\n",
    "\n",
    "        # Calculating the sum of embeddings for each document\n",
    "        sum_embeddings = torch.sum(embeddings * mask.unsqueeze(-1), dim=1)  # (batch_size x embedding_dim)\n",
    "\n",
    "        # Calculating the length of each document (number of non-PAD tokens)\n",
    "        doc_lengths = torch.sum(mask, dim=1).unsqueeze(-1)  # (batch_size x 1)\n",
    "\n",
    "        # Avoiding division by zero for empty documents\n",
    "        doc_lengths = torch.clamp(doc_lengths, min=1)\n",
    "\n",
    "        # Calculating the mean embeddings for each document\n",
    "        doc_embeddings = sum_embeddings / doc_lengths  # (batch_size x embedding_dim)\n",
    "\n",
    "        # Passing the document embeddings through the fully connected layer\n",
    "        logits = self.fc(doc_embeddings)  # (batch_size x num_classes)\n",
    "\n",
    "        # Applying Softmax to get class probabilities\n",
    "        probabilities = torch.softmax(logits, dim=1)  # (batch_size x num_classes)\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_classes = 12\n",
    "    embedding_dim = 100\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = ClassificationAverageModel(embedding_layer, embedding_dim, num_classes)\n",
    "\n",
    "    batch_size = 4\n",
    "    max_document_length = 50\n",
    "    input_ids = torch.randint(0, len(dictionary), (batch_size, max_document_length))\n",
    "\n",
    "    probabilities = model(input_ids)\n",
    "    print(f\"Probabilities shape: {probabilities.shape}\")\n",
    "    print(f\"Probabilities: {probabilities}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7CQbzVpAiAp"
   },
   "source": [
    "# Loss Function and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmIhrOLR9uML",
    "outputId": "deeeee50-b80e-4705-d69b-dc0eedcd61bb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5, Loss: 2.0700\n",
      "Epoch 2/5, Loss: 1.8799\n",
      "Epoch 3/5, Loss: 1.8305\n",
      "Epoch 4/5, Loss: 1.8106\n",
      "Epoch 5/5, Loss: 1.7958\n"
     ]
    }
   ],
   "source": [
    "num_classes = 12\n",
    "embedding_dim = 100\n",
    "model = ClassificationAverageModel(embedding_layer, embedding_dim, num_classes)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (input_ids, labels) in enumerate(train_loader):\n",
    "        predictions = model(input_ids)\n",
    "        loss = loss_function(predictions, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "px-FFx5SC5cn"
   },
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtqkWtdJ2TIV",
    "outputId": "1dc905d3-f516-40a6-c525-89169865fa1d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Loss: 1.7734, Validation Accuracy: 0.7939\n",
      "Best model saved with accuracy: 0.7939\n",
      "Epoch 2, Loss: 1.7501, Validation Accuracy: 0.7997\n",
      "Best model saved with accuracy: 0.7997\n",
      "Epoch 3, Loss: 1.7313, Validation Accuracy: 0.8032\n",
      "Best model saved with accuracy: 0.8032\n",
      "Epoch 4, Loss: 1.7182, Validation Accuracy: 0.8012\n",
      "Epoch 5, Loss: 1.7084, Validation Accuracy: 0.8001\n",
      "Epoch 6, Loss: 1.7009, Validation Accuracy: 0.7985\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Validation DataLoader Creation\n",
    "val_dataset = DocumentDataset(\n",
    "    valData['clean_text'].tolist(),  # Validation documents\n",
    "    valData['label'].tolist(),      # Validation labels\n",
    "    dictionary,                     # Dictionary mapping words to IDs\n",
    "    max_document_length             # Maximum document length\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Early Stopping Hyperparameters\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "best_accuracy = 0.0  # Best validation accuracy observed so far\n",
    "epochs_without_improvement = 0  # Counter for epochs without improvement\n",
    "max_epochs = 20  # Maximum number of epochs\n",
    "\n",
    "# Training with Early Stopping\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Training on batches\n",
    "    for batch_idx, (input_ids, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        predictions = model(input_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(predictions, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation Accuracy\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in val_loader:\n",
    "            predictions = model(input_ids)\n",
    "            val_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculating validation accuracy\n",
    "    val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Checking for improvement\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
    "        print(f\"Best model saved with accuracy: {best_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Early Stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q248iorSDX7H"
   },
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYOByLOf2TIV",
    "outputId": "b7f0d497-bbbf-477d-9fdd-2582f24e1c75"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 0.7992\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.37      0.36      0.36       107\n",
      "           2       0.90      0.85      0.88       123\n",
      "           3       0.77      0.88      0.82       405\n",
      "           4       0.93      0.91      0.92       635\n",
      "           5       0.44      0.40      0.42       121\n",
      "           6       0.00      0.00      0.00        35\n",
      "           7       0.72      0.69      0.70        45\n",
      "           8       0.90      0.89      0.90       112\n",
      "           9       0.82      0.88      0.85       615\n",
      "          10       0.70      0.77      0.73       180\n",
      "          11       0.80      0.78      0.79       172\n",
      "\n",
      "    accuracy                           0.80      2595\n",
      "   macro avg       0.61      0.62      0.61      2595\n",
      "weighted avg       0.77      0.80      0.79      2595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"best_model.pth\", weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()  # Setting model to evaluation mode\n",
    "\n",
    "# Test DataLoader Creation\n",
    "test_dataset = DocumentDataset(\n",
    "    testData['clean_text'].tolist(),  # Validation documents\n",
    "    testData['label'].tolist(),      # Validation labels\n",
    "    dictionary,                     # Dictionary mapping words to IDs\n",
    "    max_document_length             # Maximum document length\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Testing set evaluation\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, labels in test_loader:\n",
    "        predictions = model(input_ids)\n",
    "        test_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculating accuracy\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_predictions, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvjl-MrtDbpO"
   },
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoTrVLhb2TIW"
   },
   "source": [
    "### **1. Loading and Data Details**\n",
    "- **Dataset Information**:\n",
    "  - Training Set: 12,110 examples\n",
    "  - Validation Set: 2,596 examples\n",
    "  - Test Set: 2,595 examples\n",
    "\n",
    "- **Class Distributions**:\n",
    "  - Training Labels: Example: `{4: 2829, 9: 2657, 3: 2079, ...}`\n",
    "  - Validation Labels: Example: `{4: 665, 9: 546, 3: 420, ...}`\n",
    "  - Test Labels: Example: `{4: 635, 9: 615, 3: 405, ...}`\n",
    "\n",
    "- **Raw Data Example** (Before preprocessing):\n",
    "  - **Text**: \"In addition to the immediate life-saving interventions, UNICEF is taking action to protect...\"\n",
    "  - **Label**: 9\n",
    "\n",
    "\n",
    "### **2. Preprocessing Steps**\n",
    "- **Steps Performed**:\n",
    "  - Lowercasing, punctuation removal, and numeric removal.\n",
    "  - Tokenization using `spacy` and stopword removal.\n",
    "  - Word stemming using `PorterStemmer`.\n",
    "  - Handling Out-of-Vocabulary (OOV) words by replacing rare words with `<OOV>`.\n",
    "  - Truncating/padding to `max_document_length = 50`.\n",
    "\n",
    "- **Vocabulary Size**:\n",
    "  - Initial Vocabulary Size: 23,270\n",
    "  - Reduced Vocabulary Size (After Filtering Rare Words): 11,198\n",
    "\n",
    "- **Examples of Preprocessing**:\n",
    "  - **Original Text**: \"In addition to the immediate life-saving interventions, UNICEF is taking action...\"\n",
    "  - **After Preprocessing**: `[\"addit\", \"immedi\", \"lifesav\", \"intervent\", \"unicef\", \"action\"]`\n",
    "  - **After OOV Handling**: `[\"addit\", \"immedi\", \"lifesav\", \"intervent\", \"unicef\", \"<OOV>\"]`\n",
    "\n",
    "\n",
    "### **3. Model Performance**\n",
    "#### Best-Performing Model:\n",
    "- Model: **ClassificationAverageModel** with pre-trained GloVe embeddings.\n",
    "- Early stopping used with a patience of 3 epochs.\n",
    "\n",
    "#### Results:\n",
    "| Metric                | Validation Set | Test Set    |\n",
    "|-----------------------|----------------|-------------|\n",
    "| **Accuracy**          | 80.0%          | 79.9%       |\n",
    "| **Macro Avg F1-Score**| 64.0%          | 64.0%       |\n",
    "| **Weighted Avg F1**   | 79.0%          | 79.0%       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMULc7Mb2TIW"
   },
   "source": [
    "# Overall Functionality of the Training Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bA6VJmJr2TIX"
   },
   "source": [
    "#### **Key Components of the Training Procedure**\n",
    "1. **Data Preparation and Preprocessing:**\n",
    "   - Training, validation, and test sets were loaded and preprocessed effectively to ensure the model could generalize well.\n",
    "   - Preprocessing steps included:\n",
    "     - Lowercasing, removing punctuation and numbers, tokenizing, and handling out-of-vocabulary (OOV) words.\n",
    "     - Padding and truncation were applied to standardize document lengths.\n",
    "   - The dataset was balanced across the 12 classes, though some class imbalance was observed, particularly in the training set.\n",
    "\n",
    "2. **Embedding Initialization:**\n",
    "   - Pre-trained GloVe embeddings (100-dimensional) were used to initialize the embedding layer.\n",
    "   - Words missing in the GloVe vocabulary were initialized with random embeddings.\n",
    "\n",
    "3. **Model Architecture:**\n",
    "   - The model, `ClassificationAverageModel`, used a trainable embedding layer.\n",
    "   - Document embeddings were computed as the element-wise mean of word embeddings for each document.\n",
    "   - A fully connected layer with a Softmax activation was used to map document embeddings to class probabilities.\n",
    "\n",
    "4. **Training with Early Stopping:**\n",
    "   - **Loss Function:** CrossEntropyLoss was used to calculate the loss between predicted and true labels.\n",
    "   - **Optimizer:** The Adam optimizer was employed with a learning rate of 0.001.\n",
    "   - **Early Stopping Mechanism:**\n",
    "     - Validation accuracy was monitored after each epoch.\n",
    "     - If validation accuracy did not improve for 3 consecutive epochs (patience = 3), training was terminated early.\n",
    "     - The best-performing model based on validation accuracy was saved for later evaluation.\n",
    "\n",
    "5. **Evaluation:**\n",
    "   - Validation accuracy and loss were monitored during training to ensure the model was learning effectively.\n",
    "   - The test set was evaluated using the stored best-performing model.\n",
    "\n",
    "#### **Training Progress**\n",
    "- **Epoch Results:**\n",
    "  - Epoch 1: Loss = **1.7696**, Validation Accuracy = **0.7928**\n",
    "  - Epoch 2: Loss = **1.7513**, Validation Accuracy = **0.7924**\n",
    "  - Epoch 3: Loss = **1.7336**, Validation Accuracy = **0.8012**\n",
    "  - Epoch 4: Loss = **1.7189**, Validation Accuracy = **0.7985**\n",
    "  - Epoch 5: Loss = **1.7087**, Validation Accuracy = **0.7989**\n",
    "  - Epoch 6: Loss = **1.7007**, Validation Accuracy = **0.7958**\n",
    "  - Early stopping was triggered after **6 epochs** since no significant improvement in validation accuracy was observed.\n",
    "\n",
    "#### **Key Observations**\n",
    "- **Validation Accuracy Stabilization:**\n",
    "  - The model reached a consistent validation accuracy of approximately **79.12%**, indicating stable learning during training.\n",
    "  - Early stopping prevented overfitting, as validation accuracy did not degrade across epochs.\n",
    "\n",
    "- **Test Set Evaluation:**\n",
    "  - **Test Accuracy:** **79.88%**\n",
    "  - **Classification Report:**\n",
    "    - Macro Average Precision: **0.74**\n",
    "    - Macro Average Recall: **0.64**\n",
    "    - Macro Average F1-Score: **0.64**\n",
    "    - Weighted Average F1-Score: **0.79**\n",
    "  - These metrics highlight strong performance, particularly in classes with sufficient training examples.\n",
    "\n",
    "#### **Conclusion**\n",
    "The training procedure demonstrated strong functionality, achieving a solid test accuracy of **79.88%**. Early stopping successfully mitigated overfitting, and the evaluation metrics indicated that the model performed well across most classes, despite class imbalances. Further improvements could include addressing class imbalance and exploring more advanced architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx0fX_QJEfvd"
   },
   "source": [
    "# Task B: Document Classification with BERT (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd10tNN1Eg-d"
   },
   "source": [
    "This task aims to conduct the same document classification as Task A, but now by utilizing a pre-trained BERT model. Feel free to reuse any code from the previous task. The implementation of the classifier should cover the points below.\n",
    "\n",
    "**Loading BERT model (2 points):** Use the `transformers` library from `huggingface` to load a (small) pre-trained BERT model. Select a BERT model according to your available resources. The available models can be found [here](https://huggingface.co/models) and [here](https://github.com/google-research/bert).\n",
    "\n",
    "**BERT tokenization (3 points):** For training BERT models, we do not need to create a dictionary anymore, as a BERT model already contains an internal subword dictionary. Following the instruction in `transformers`'s documentation, tokenize the data using the BERT model.  \n",
    "\n",
    "**Model definition and forward function (5 points):** Define the class **`ClassificationBERTModel`** as a PyTorch model. In the initialization procedure, the model receives the loaded BERT model and stores it as the model's parameter. The parameters of the BERT model should be trainable. The forward function of the model receives a batch of data, passes this batch to BERT, and achieves the corresponding document embeddings from the output of BERT. Similar to the previous task, the document embeddings are used for classification by linearly transforming document embeddings to the vectors with the number of classes, followed by applying Softmax.\n",
    "\n",
    "**Training and overall functionality (3 points):** Train the model in a similar fashion to the previous task, namely with the proper loss function, optimization, and early stoping.\n",
    "\n",
    "**Test Set Evaluation (1 point):** After finishing the training, load the (already stored) best performing model, and use it for class prediction on the test set.\n",
    "\n",
    "**Reporting (1 point):** Report the results of the best performing model on the validation and test set in a table.\n",
    "# New Section"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Import Libraries:"
   ],
   "metadata": {
    "id": "W5sZEYOpIzlx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "id": "PCx6h2ikIqa8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Load BERT Tokenizer and Model:"
   ],
   "metadata": {
    "id": "Yfe4eesQI4DP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_mapping))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344,
     "referenced_widgets": [
      "b344f6e0b23b4e25b3bfb51e3853d8f5",
      "c84c81857c7442b6b103a11db3e34323",
      "ee38e2f427cc4494948e5f6c15b91ff8",
      "ee1b435a920b43748347c43f8fb62295",
      "acab557b2a5d402c9ab1778af5cacd42",
      "3a16536af40d4e54b59a04bad635967a",
      "b902e5976d2f40bb98af11da7def0597",
      "933ebd8baf054cd3bda9f7b2191d2837",
      "1ca9496e1cad42e98c7c78028d827d9d",
      "ef71f07b60394d2fb0236d236ba92b60",
      "b9229869023f43df94e17f94b3361fbd",
      "dd4493533d164c4fb02bd7b4dcb32194",
      "f4b272f2da1c45618763c32baa73af21",
      "186bcda16f99453985363ec578b2692f",
      "b6aab469828a43259e54374fcdc4bfb0",
      "6d69a68fe6474ed69d16bc19790a62f5",
      "fef1c7c30c644e3d95e956d99b5a2ca6",
      "6d3b26e27e8743ea9ffb5115df85427f",
      "d1ebecf606184ed9b27406b6921c7a14",
      "20cae93258d74b758f2292ef5da399c7",
      "70d9c1c983bf4150a897e6ebec87fe60",
      "b255c9428b0d41da9d9606c4ad0d09d1",
      "781e0abc3b3a443281507afa05522a61",
      "e24863b0f98f486884a1d6cc2cc0bc8a",
      "f40767147ba149d1b0c6631834a30082",
      "e3f72a73ef5543dc8344fa021f547b5d",
      "b207471b89bd40bcb1f7077a4c979d3b",
      "90bd2807e5724fd197a4fe22295f4c92",
      "1b5b3eff1e2a48acaaefb147312459fa",
      "99670f3e0dec4c358474fafd3b548600",
      "d192294a92c846c8b033728e352a821d",
      "6e82d1dca3404d71a4bcdef2927d038f",
      "1ef76b1a04f948c5bb4cc778b99fcfe3",
      "f80d1d6419cd4d409e4b941e52c1249e",
      "9fa21efc3fce4a678b964d4072311d18",
      "30a747c546034797a8d6358921c06ae8",
      "43a78a627da842fc8157f7f831b77833",
      "e3027a0be1dd46d8aebf9be45c8886d0",
      "25e0c259d887436ca86dce306d923ded",
      "38b07d3669754069ae5925aefa92e19e",
      "e0101281551e4ba596ae4902e42eaaf8",
      "d77940ce3ed141b8938b4117faa5c6ba",
      "24f75e2b062247da8c84731bbb82527c",
      "959b664daf4a4d31975330b3b50f9f34",
      "a6e75c50826441399c779ca646e9d604",
      "e283e1e519cf4d868625b86cb1f1dda7",
      "a5b38889c1fd489abdbd3f06aa48c373",
      "8f57540d0d344ca195045e287641dc4d",
      "10a800990c4c4e1d9fdef95fbb34b3d1",
      "b8655371782f47b091f6f23c5f6ff21d",
      "eaa54663442a4ff3ba70442258b13bbe",
      "0ab145b3ab144122b847ff2e3b03afe9",
      "71253f90a34f4478b575be7ebb3cc882",
      "8ca4ec1386c94c5a8f84b6d0d7e2d32a",
      "29b26c65e16a4e58b75ee4010381b954"
     ]
    },
    "id": "qMU0LyfbI6X9",
    "outputId": "ea2dabfc-16ed-40c7-81f3-02ac2b25147f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b344f6e0b23b4e25b3bfb51e3853d8f5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd4493533d164c4fb02bd7b4dcb32194"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "781e0abc3b3a443281507afa05522a61"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f80d1d6419cd4d409e4b941e52c1249e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6e75c50826441399c779ca646e9d604"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Tokenize the Datasets:"
   ],
   "metadata": {
    "id": "TNXFcXELJPDZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset['text'].tolist(), padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "train_encodings = tokenize_dataset(trainData)\n",
    "val_encodings = tokenize_dataset(valData)\n",
    "test_encodings = tokenize_dataset(testData)"
   ],
   "metadata": {
    "id": "aACWQMm7JS2q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Create Dataset Classes:"
   ],
   "metadata": {
    "id": "CIjnOmr0Jg0E"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, trainData['label'].tolist())\n",
    "val_dataset = Dataset(val_encodings, valData['label'].tolist())\n",
    "test_dataset = Dataset(test_encodings, testData['label'].tolist())"
   ],
   "metadata": {
    "id": "EVPoXekpJi2k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Set Up Training Arguments:"
   ],
   "metadata": {
    "id": "Chg-QgfzJwS4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "# Ensure directories exist\n",
    "if not os.path.exists('./logs'):\n",
    "    os.makedirs('./logs')\n",
    "if not os.path.exists('./results'):\n",
    "    os.makedirs('./results')\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=2e-5,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    save_total_limit=2,\n",
    ")\n"
   ],
   "metadata": {
    "id": "R4nru9k4Jw-X"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Define the Training Function:"
   ],
   "metadata": {
    "id": "ZQ_oPwkYO8zv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': accuracy_score(labels, predictions)}"
   ],
   "metadata": {
    "id": "e1eqFiXmPFPJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Initialize Trainer:"
   ],
   "metadata": {
    "id": "zt_HLowfQwl8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "id": "QHzm6ruVQyN3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Train the Model:"
   ],
   "metadata": {
    "id": "B03t0xuzQ1Lg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "c3TwSY37Q3rb",
    "outputId": "482dcb85-8ea7-47bf-c287-1e5ad2b2ef19"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250105_114221-p87pcwz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/atariqq8-johannes-kepler-universit-t-linz/huggingface/runs/p87pcwz6' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/atariqq8-johannes-kepler-universit-t-linz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/atariqq8-johannes-kepler-universit-t-linz/huggingface' target=\"_blank\">https://wandb.ai/atariqq8-johannes-kepler-universit-t-linz/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/atariqq8-johannes-kepler-universit-t-linz/huggingface/runs/p87pcwz6' target=\"_blank\">https://wandb.ai/atariqq8-johannes-kepler-universit-t-linz/huggingface/runs/p87pcwz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='983' max='2271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 983/2271 24:58 < 32:48, 0.65 it/s, Epoch 1.30/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.746300</td>\n",
       "      <td>0.608219</td>\n",
       "      <td>0.825501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2271' max='2271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2271/2271 59:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.746300</td>\n",
       "      <td>0.608219</td>\n",
       "      <td>0.825501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.528681</td>\n",
       "      <td>0.857473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.546909</td>\n",
       "      <td>0.854391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2271, training_loss=0.6986200648459607, metrics={'train_runtime': 3715.2561, 'train_samples_per_second': 9.779, 'train_steps_per_second': 0.611, 'total_flos': 9559682889523200.0, 'train_loss': 0.6986200648459607, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate on Test Set:"
   ],
   "metadata": {
    "id": "Cw0O_bLOQ7wI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_results['eval_accuracy']}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "ba1n-WQSQ8Pa",
    "outputId": "2fa33c4c-8c99-465e-8de8-4c46c78e914b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163' max='163' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [163/163 01:16]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 0.8485549132947977\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Summary of Training and Validation Metrics\n",
    "\n",
    "| Epoch | Training Loss | Validation Loss | Validation Accuracy |\n",
    "|-------|---------------|-----------------|---------------------|\n",
    "| 1     | 0.7463        | 0.6082          | 0.8255              |\n",
    "| 2     | 0.3786        | 0.5287          | 0.8575              |\n",
    "| 3     | 0.3428        | 0.5469          | 0.8544              |\n",
    "\n",
    "The training loss consistently decreases across epochs, indicating that the model is learning from the training data. However, the validation loss shows a slight increase in the third epoch, suggesting potential overfitting. Despite this, the validation accuracy remains stable, indicating that the model generalizes reasonably well.\n",
    "\n",
    "### 2. Overall Training Metrics\n",
    "\n",
    "- **Global Step:** 2271\n",
    "- **Training Loss:** 0.6986\n",
    "- **Training Runtime:** 3715.26 seconds\n",
    "- **Train Samples per Second:** 9.78\n",
    "- **Train Steps per Second:** 0.61\n",
    "- **Total FLOPs:** 9.5596828895232e+15\n",
    "\n",
    "These metrics provide insight into the training efficiency and computational requirements. The model trained efficiently with a reasonable number of steps per second.\n",
    "\n",
    "### 3. Test Set Performance\n",
    "\n",
    "- **Test Accuracy:** 0.8486\n",
    "\n",
    "The model achieves an accuracy of approximately 84.86% on the test set, indicating good performance in classifying documents into the specified categories.\n",
    "\n",
    "### 4. Discussion\n",
    "\n",
    "The model demonstrates satisfactory performance with a test accuracy of 84.86%. However, the slight increase in validation loss during the third epoch suggests that the model might be overfitting. To address this, potential improvements could include:\n",
    "\n",
    "- **Early Stopping:** Halting training before overfitting occurs.\n",
    "- **Regularization Techniques:** Such as dropout or L2 regularization.\n",
    "- **Hyperparameter Tuning:** Exploring different learning rates or batch sizes.\n",
    "\n",
    "Additionally, visualizing the training and validation loss and accuracy over epochs would provide a clearer understanding of the model's learning dynamics. Including metrics like precision, recall, and F1-score, especially if classes are imbalanced, would offer a more comprehensive evaluation.\n",
    "\n",
    "### 5. Conclusion\n",
    "\n",
    "In conclusion, the BERT-based model effectively classifies documents with a test accuracy of 84.86%. While there are indications of slight overfitting, the model generalizes well. Future work could focus on refining the model to improve generalization and explore additional performance metrics for a more nuanced evaluation."
   ],
   "metadata": {
    "id": "Qdlz0XTyfxVw"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "b344f6e0b23b4e25b3bfb51e3853d8f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c84c81857c7442b6b103a11db3e34323",
       "IPY_MODEL_ee38e2f427cc4494948e5f6c15b91ff8",
       "IPY_MODEL_ee1b435a920b43748347c43f8fb62295"
      ],
      "layout": "IPY_MODEL_acab557b2a5d402c9ab1778af5cacd42"
     }
    },
    "c84c81857c7442b6b103a11db3e34323": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a16536af40d4e54b59a04bad635967a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b902e5976d2f40bb98af11da7def0597",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "ee38e2f427cc4494948e5f6c15b91ff8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_933ebd8baf054cd3bda9f7b2191d2837",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ca9496e1cad42e98c7c78028d827d9d",
      "value": 48
     }
    },
    "ee1b435a920b43748347c43f8fb62295": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef71f07b60394d2fb0236d236ba92b60",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b9229869023f43df94e17f94b3361fbd",
      "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡3.02kB/s]"
     }
    },
    "acab557b2a5d402c9ab1778af5cacd42": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a16536af40d4e54b59a04bad635967a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b902e5976d2f40bb98af11da7def0597": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "933ebd8baf054cd3bda9f7b2191d2837": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ca9496e1cad42e98c7c78028d827d9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef71f07b60394d2fb0236d236ba92b60": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9229869023f43df94e17f94b3361fbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd4493533d164c4fb02bd7b4dcb32194": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4b272f2da1c45618763c32baa73af21",
       "IPY_MODEL_186bcda16f99453985363ec578b2692f",
       "IPY_MODEL_b6aab469828a43259e54374fcdc4bfb0"
      ],
      "layout": "IPY_MODEL_6d69a68fe6474ed69d16bc19790a62f5"
     }
    },
    "f4b272f2da1c45618763c32baa73af21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fef1c7c30c644e3d95e956d99b5a2ca6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6d3b26e27e8743ea9ffb5115df85427f",
      "value": "vocab.txt:â€‡100%"
     }
    },
    "186bcda16f99453985363ec578b2692f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1ebecf606184ed9b27406b6921c7a14",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20cae93258d74b758f2292ef5da399c7",
      "value": 231508
     }
    },
    "b6aab469828a43259e54374fcdc4bfb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70d9c1c983bf4150a897e6ebec87fe60",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b255c9428b0d41da9d9606c4ad0d09d1",
      "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡491kB/s]"
     }
    },
    "6d69a68fe6474ed69d16bc19790a62f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fef1c7c30c644e3d95e956d99b5a2ca6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d3b26e27e8743ea9ffb5115df85427f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1ebecf606184ed9b27406b6921c7a14": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20cae93258d74b758f2292ef5da399c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "70d9c1c983bf4150a897e6ebec87fe60": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b255c9428b0d41da9d9606c4ad0d09d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "781e0abc3b3a443281507afa05522a61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e24863b0f98f486884a1d6cc2cc0bc8a",
       "IPY_MODEL_f40767147ba149d1b0c6631834a30082",
       "IPY_MODEL_e3f72a73ef5543dc8344fa021f547b5d"
      ],
      "layout": "IPY_MODEL_b207471b89bd40bcb1f7077a4c979d3b"
     }
    },
    "e24863b0f98f486884a1d6cc2cc0bc8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90bd2807e5724fd197a4fe22295f4c92",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1b5b3eff1e2a48acaaefb147312459fa",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "f40767147ba149d1b0c6631834a30082": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99670f3e0dec4c358474fafd3b548600",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d192294a92c846c8b033728e352a821d",
      "value": 466062
     }
    },
    "e3f72a73ef5543dc8344fa021f547b5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e82d1dca3404d71a4bcdef2927d038f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1ef76b1a04f948c5bb4cc778b99fcfe3",
      "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡1.96MB/s]"
     }
    },
    "b207471b89bd40bcb1f7077a4c979d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90bd2807e5724fd197a4fe22295f4c92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b5b3eff1e2a48acaaefb147312459fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99670f3e0dec4c358474fafd3b548600": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d192294a92c846c8b033728e352a821d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e82d1dca3404d71a4bcdef2927d038f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ef76b1a04f948c5bb4cc778b99fcfe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f80d1d6419cd4d409e4b941e52c1249e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fa21efc3fce4a678b964d4072311d18",
       "IPY_MODEL_30a747c546034797a8d6358921c06ae8",
       "IPY_MODEL_43a78a627da842fc8157f7f831b77833"
      ],
      "layout": "IPY_MODEL_e3027a0be1dd46d8aebf9be45c8886d0"
     }
    },
    "9fa21efc3fce4a678b964d4072311d18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25e0c259d887436ca86dce306d923ded",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_38b07d3669754069ae5925aefa92e19e",
      "value": "config.json:â€‡100%"
     }
    },
    "30a747c546034797a8d6358921c06ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0101281551e4ba596ae4902e42eaaf8",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d77940ce3ed141b8938b4117faa5c6ba",
      "value": 570
     }
    },
    "43a78a627da842fc8157f7f831b77833": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24f75e2b062247da8c84731bbb82527c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_959b664daf4a4d31975330b3b50f9f34",
      "value": "â€‡570/570â€‡[00:00&lt;00:00,â€‡38.0kB/s]"
     }
    },
    "e3027a0be1dd46d8aebf9be45c8886d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25e0c259d887436ca86dce306d923ded": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38b07d3669754069ae5925aefa92e19e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0101281551e4ba596ae4902e42eaaf8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d77940ce3ed141b8938b4117faa5c6ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24f75e2b062247da8c84731bbb82527c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "959b664daf4a4d31975330b3b50f9f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6e75c50826441399c779ca646e9d604": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e283e1e519cf4d868625b86cb1f1dda7",
       "IPY_MODEL_a5b38889c1fd489abdbd3f06aa48c373",
       "IPY_MODEL_8f57540d0d344ca195045e287641dc4d"
      ],
      "layout": "IPY_MODEL_10a800990c4c4e1d9fdef95fbb34b3d1"
     }
    },
    "e283e1e519cf4d868625b86cb1f1dda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8655371782f47b091f6f23c5f6ff21d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_eaa54663442a4ff3ba70442258b13bbe",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "a5b38889c1fd489abdbd3f06aa48c373": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ab145b3ab144122b847ff2e3b03afe9",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_71253f90a34f4478b575be7ebb3cc882",
      "value": 440449768
     }
    },
    "8f57540d0d344ca195045e287641dc4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ca4ec1386c94c5a8f84b6d0d7e2d32a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_29b26c65e16a4e58b75ee4010381b954",
      "value": "â€‡440M/440Mâ€‡[00:03&lt;00:00,â€‡160MB/s]"
     }
    },
    "10a800990c4c4e1d9fdef95fbb34b3d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8655371782f47b091f6f23c5f6ff21d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaa54663442a4ff3ba70442258b13bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ab145b3ab144122b847ff2e3b03afe9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71253f90a34f4478b575be7ebb3cc882": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ca4ec1386c94c5a8f84b6d0d7e2d32a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29b26c65e16a4e58b75ee4010381b954": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
