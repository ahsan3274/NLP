{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aMfkh9s0hNT"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geqo_zBx0hNW"
   },
   "source": [
    "<h2 style=\"text-align: center\">344.105/6/7 > Natural Language Processing (WS2023/24)</h2>\n",
    "\n",
    "<h2 style=\"color:rgb(0,120,170)\">Getting to Know Word Embedding!</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDEuFk6r0hNW"
   },
   "source": [
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University (JKU) Linz, and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "**Authors:** Shah Nawaz, Shahed Masoudian<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ud2FEEI0hNX"
   },
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-taskA\"><li style=\"font-size:large;font-weight:bold\">Task A: Words Similarity and Nearest Neighbors (15 points)</li></a>\n",
    "    <a href=\"#section-taskB\"><li style=\"font-size:large;font-weight:bold\">Task B: Document Classification with Word Embedding (15 points)</li></a>\n",
    "    <a href=\"#section-taskC\"><li style=\"font-size:large;font-weight:bold\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</li></a>\n",
    "    <a href=\"#section-references\"><li style=\"font-size:large;font-weight:bold\">References</li></a>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyuA3mSo0hNX"
   },
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTUmsuSy0hNX"
   },
   "source": [
    "### Assignment objective\n",
    "The aim of this assignment is to get familiarized with using word embedding (WE) models in practice. The assignment in total has **30 points**; it also offers **2 extra points** which can cover any missing point.\n",
    "\n",
    "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way!\n",
    "\n",
    "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQOVXyB30hNX"
   },
   "source": [
    "### Libraries & Dataset\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python` (>3.7). Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "To conduct the experiments, we use a subset of the `HumSet` dataset [1] (https://blog.thedeep.io/humset/). `HumSet` is created by the DEEP (https://www.thedeep.io) project – an open source platform which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset contains the classes (labels) referring to the humanitarian sectors like agriculture, health, and protection. The dataset contains an overall number of 17,301 data points.\n",
    "\n",
    "Download the dataset from the Moodle page of the course.\n",
    "\n",
    "the provided zip file consists of the following files:\n",
    "- `thedeep.subset.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.label.txt`: Captions of the labels.\n",
    "- `thedeep.ToU.txt`: Terms of use of the dataset.\n",
    "\n",
    "[1] HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response\n",
    "*Selim Fekih, Nicolo' Tamagnone, Benjamin Minixhofer, Ranjan Shrestha, Ximena Contla, Ewan Oglethorpe and Navid Rekabsaz.*\n",
    "In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP), December 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox-N-m280hNY"
   },
   "source": [
    "## Style\n",
    "\n",
    "- Please provide evidence at each state by giving print of the results, provide tables, graphs to further improve the quality of your report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o2byJ7O0hNY"
   },
   "source": [
    "\n",
    "### Submission\n",
    "\n",
    "Each group should submit the following two files:\n",
    "\n",
    "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook.\n",
    "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
    "\n",
    "You do not need to include the data files in the submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lv70A7t30hNY"
   },
   "source": [
    "<a name=\"section-taskA\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Words Similarity and Nearest Neighbors (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3tDVZZW0hNY"
   },
   "source": [
    "\n",
    "**Loading a word embedding (WE) model (1 points).** Download a pre-trained word embedding model such as word2vec (https://code.google.com/archive/p/word2vec/) or GloVe (https://nlp.stanford.edu/projects/glove/). You can load the downloaded vectors into arrays, or use libraries such as `gensim` to download and process the vectors.\n",
    "\n",
    "**Calculating word-to-word similarities (4 points).** Select <ins>5 arbitrary words</ins> from 5 different topics like objects, science disciplines, verbs, adjectives, animals, etc. Let us refer to these words as *source words*. For each source word, calculate its cosine similarities to <ins>6 target words</ins>. The target words of each source word are also selected by you and should cover various levels of semantic relations – according to your linguistic judgement – to the source word, namely from highly-related to not related at all. Organize the target words in tables, such that the target words of each source word are sorted from the highest to the lowest relevance (according to your judgement). Consider the following points:\n",
    "\n",
    "- **Implementation (2/4 points):** Implement cosine similarity as a function that takes two vectors and returns the similarity score. Implement cosine by yourself and do NOT use the provided functionalities of any library.\n",
    "- **Reporting and observations (2/4 points):** Report the calculated similarities side by side with your word-to-word semantic relevance judgements in tables. Compare the results and report your observations.  \n",
    "\n",
    "**Calculating nearest neighbors (10 points).** For the 5 source words, retrieve the $k=10$ nearest neighbors using the word embedding model, namely the words with the highest similarities to the source word. Consider the following points:\n",
    "    \n",
    "- **Overall implementation (3/10 points):** your implemented function takes a source vector, a set of target vectors, and the $k$ parameter, and returns the $k$ nearest neighbors and their similarity scores. Implement nearest neighbor calculation by yourself and do NOT use the provided functionalities of any library.\n",
    "- **Similarity metrics (2/10 points):** execute the calculation of nearest neighbors according to <ins>two similarity metrics</ins> namely cosine and dot product.\n",
    "- **Efficiency (3/10 points):** your nearest neighbor functions should provide an *efficient* calculation of nearest neighbors. An inefficient way (which should be avoided!) would be looping over the set of vectors in the word embedding model, and one by one calculating the cosine/dot product similarity of the source vector to each of the target vectors. As a hint for an efficient way, consider that in `numpy` (and other libraries), calculating the dot product of a vector to a matrix is much faster than the dot products of the vector to each vector of the matrix.\n",
    "- **Reporting and observations (2/10 points):** report the results in tables, which enable comparing between the outputs of the two similarity metrics. Which similarity metric would you prefer? Report your observations.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T05:19:46.103519Z",
     "start_time": "2024-12-06T05:19:46.014863Z"
    },
    "id": "Sw0KtijY0hNZ",
    "outputId": "67882f30-4245-465b-afd9-386fb8157939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 400000/400000 [00:07<00:00, 51518.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words with dimension 100\n",
      "\n",
      "=== Word-to-Word Similarity Analysis ===\n",
      "\n",
      "Analysis for source word: 'computer'\n",
      "+---------------+--------------------------------------------------+---------------------+\n",
      "| Target Word   | Linguistic Judgment                              |   Cosine Similarity |\n",
      "+===============+==================================================+=====================+\n",
      "| software      | Related - necessary non-physical component       |              0.8373 |\n",
      "+---------------+--------------------------------------------------+---------------------+\n",
      "| laptop        | Very similar - same category of computing device |              0.7024 |\n",
      "+---------------+--------------------------------------------------+---------------------+\n",
      "| keyboard      | Highly related - essential peripheral component  |              0.5418 |\n",
      "+---------------+--------------------------------------------------+---------------------+\n",
      "| desk          | Contextually related - common location           |              0.3806 |\n",
      "+---------------+--------------------------------------------------+---------------------+\n",
      "| banana        | Unrelated - different domain (food)              |              0.1213 |\n",
      "+---------------+--------------------------------------------------+---------------------+\n",
      "| sadness       | Abstract and unrelated - emotion concept         |              0.0277 |\n",
      "+---------------+--------------------------------------------------+---------------------+\n",
      "\n",
      "Nearest Neighbors Comparison:\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|   Rank | Cosine Neighbor   |   Cosine Sim | Dot Product Neighbor   |   Dot Score |\n",
      "+========+===================+==============+========================+=============+\n",
      "|      1 | computer          |       1      | computer               |     42.6299 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      2 | computers         |       0.8752 | software               |     35.4423 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      3 | software          |       0.8373 | computers              |     34.6337 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      4 | technology        |       0.7642 | technology             |     31.4114 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      5 | pc                |       0.7366 | internet               |     30.1825 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      6 | hardware          |       0.729  | microsoft              |     29.3901 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      7 | internet          |       0.7287 | digital                |     29.297  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      8 | desktop           |       0.7234 | systems                |     29.2211 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      9 | electronic        |       0.7222 | pc                     |     29.0088 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|     10 | systems           |       0.7198 | desktop                |     28.9946 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "\n",
      "Metric Comparison:\n",
      "Common words between metrics: 8 out of 10\n",
      "Significant ranking differences:\n",
      "'pc': Cosine rank 5, Dot rank 9\n",
      "\n",
      "Analysis for source word: 'biology'\n",
      "+---------------+---------------------------------------------+---------------------+\n",
      "| Target Word   | Linguistic Judgment                         |   Cosine Similarity |\n",
      "+===============+=============================================+=====================+\n",
      "| chemistry     | Similar field - related natural science     |              0.8058 |\n",
      "+---------------+---------------------------------------------+---------------------+\n",
      "| science       | Parent category - field of study            |              0.7383 |\n",
      "+---------------+---------------------------------------------+---------------------+\n",
      "| research      | Related activity - general academic concept |              0.6446 |\n",
      "+---------------+---------------------------------------------+---------------------+\n",
      "| poetry        | Unrelated field - arts domain               |              0.3627 |\n",
      "+---------------+---------------------------------------------+---------------------+\n",
      "| microscope    | Related tool - common instrument            |              0.2468 |\n",
      "+---------------+---------------------------------------------+---------------------+\n",
      "| bicycle       | Unrelated object - transportation domain    |              0.0007 |\n",
      "+---------------+---------------------------------------------+---------------------+\n",
      "\n",
      "Nearest Neighbors Comparison:\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|   Rank | Cosine Neighbor   |   Cosine Sim | Dot Product Neighbor   |   Dot Score |\n",
      "+========+===================+==============+========================+=============+\n",
      "|      1 | biology           |       1      | biology                |     36.2488 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      2 | biochemistry      |       0.8498 | physics                |     30.1124 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      3 | chemistry         |       0.8058 | chemistry              |     28.873  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      4 | genetics          |       0.7997 | biochemistry           |     28.7983 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      5 | physics           |       0.7895 | science                |     27.7274 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      6 | physiology        |       0.7822 | sciences               |     27.241  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      7 | psychology        |       0.7639 | physiology             |     27.008  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      8 | mathematics       |       0.7575 | molecular              |     26.4804 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      9 | neuroscience      |       0.7441 | psychology             |     26.402  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|     10 | science           |       0.7383 | mathematics            |     26.382  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "\n",
      "Metric Comparison:\n",
      "Common words between metrics: 8 out of 10\n",
      "Significant ranking differences:\n",
      "'science': Cosine rank 10, Dot rank 5\n",
      "\n",
      "Analysis for source word: 'dancing'\n",
      "+---------------+----------------------------------------+---------------------+\n",
      "| Target Word   | Linguistic Judgment                    |   Cosine Similarity |\n",
      "+===============+========================================+=====================+\n",
      "| music         | Related context - accompanying element |              0.5824 |\n",
      "+---------------+----------------------------------------+---------------------+\n",
      "| jumping       | Related movement - common component    |              0.5788 |\n",
      "+---------------+----------------------------------------+---------------------+\n",
      "| spinning      | Very similar action - core movement    |              0.3994 |\n",
      "+---------------+----------------------------------------+---------------------+\n",
      "| exercise      | Related concept - physical activity    |              0.3591 |\n",
      "+---------------+----------------------------------------+---------------------+\n",
      "| pencil        | Unrelated object - writing tool        |              0.1389 |\n",
      "+---------------+----------------------------------------+---------------------+\n",
      "| algebra       | Unrelated concept - mathematics domain |              0.0699 |\n",
      "+---------------+----------------------------------------+---------------------+\n",
      "\n",
      "Nearest Neighbors Comparison:\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|   Rank | Cosine Neighbor   |   Cosine Sim | Dot Product Neighbor   |   Dot Score |\n",
      "+========+===================+==============+========================+=============+\n",
      "|      1 | dancing           |       1      | dancing                |     31.6157 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      2 | dance             |       0.8293 | dance                  |     28.3693 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      3 | singing           |       0.8056 | singing                |     26.4059 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      4 | dances            |       0.7744 | dancers                |     24.4515 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      5 | dancers           |       0.7681 | dances                 |     23.6417 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      6 | danced            |       0.705  | music                  |     22.0194 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      7 | ballroom          |       0.6582 | ballet                 |     21.072  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      8 | onstage           |       0.6422 | danced                 |     20.9621 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      9 | dancer            |       0.641  | girls                  |     20.4152 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|     10 | girls             |       0.6151 | ballroom               |     20.4021 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "\n",
      "Metric Comparison:\n",
      "Common words between metrics: 8 out of 10\n",
      "Significant ranking differences:\n",
      "\n",
      "Analysis for source word: 'beautiful'\n",
      "+---------------+-------------------------------------------+---------------------+\n",
      "| Target Word   | Linguistic Judgment                       |   Cosine Similarity |\n",
      "+===============+===========================================+=====================+\n",
      "| gorgeous      | Synonym - same meaning                    |              0.8722 |\n",
      "+---------------+-------------------------------------------+---------------------+\n",
      "| elegant       | Similar concept - positive aesthetic      |              0.7176 |\n",
      "+---------------+-------------------------------------------+---------------------+\n",
      "| attractive    | Related concept - positive appearance     |              0.5877 |\n",
      "+---------------+-------------------------------------------+---------------------+\n",
      "| rainbow       | Associated object - aesthetic phenomenon  |              0.375  |\n",
      "+---------------+-------------------------------------------+---------------------+\n",
      "| calculate     | Unrelated action - mathematical operation |              0.0403 |\n",
      "+---------------+-------------------------------------------+---------------------+\n",
      "| wrench        | Unrelated object - tool                   |             -0.0099 |\n",
      "+---------------+-------------------------------------------+---------------------+\n",
      "\n",
      "Nearest Neighbors Comparison:\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|   Rank | Cosine Neighbor   |   Cosine Sim | Dot Product Neighbor   |   Dot Score |\n",
      "+========+===================+==============+========================+=============+\n",
      "|      1 | beautiful         |       1      | beautiful              |     33.4834 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      2 | lovely            |       0.8909 | lovely                 |     24.5335 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      3 | gorgeous          |       0.8722 | wonderful              |     23.2594 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      4 | wonderful         |       0.8081 | gorgeous               |     21.806  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      5 | charming          |       0.7719 | pretty                 |     21.5952 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      6 | magnificent       |       0.7332 | love                   |     21.5259 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      7 | elegant           |       0.7176 | very                   |     21.4354 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      8 | fabulous          |       0.6914 | my                     |     21.2832 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      9 | splendid          |       0.685  | elegant                |     21.2742 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|     10 | perfect           |       0.6778 | charming               |     21.1159 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "\n",
      "Metric Comparison:\n",
      "Common words between metrics: 6 out of 10\n",
      "Significant ranking differences:\n",
      "'charming': Cosine rank 5, Dot rank 10\n",
      "\n",
      "Analysis for source word: 'elephant'\n",
      "+---------------+--------------------------------------------+---------------------+\n",
      "| Target Word   | Linguistic Judgment                        |   Cosine Similarity |\n",
      "+===============+============================================+=====================+\n",
      "| giraffe       | Similar category - large mammal            |              0.6181 |\n",
      "+---------------+--------------------------------------------+---------------------+\n",
      "| zoo           | Related location - common environment      |              0.5342 |\n",
      "+---------------+--------------------------------------------+---------------------+\n",
      "| safari        | Related context - habitat/viewing          |              0.4972 |\n",
      "+---------------+--------------------------------------------+---------------------+\n",
      "| trunk         | Part-whole relation - body part            |              0.3398 |\n",
      "+---------------+--------------------------------------------+---------------------+\n",
      "| calculator    | Unrelated object - electronic device       |              0.1557 |\n",
      "+---------------+--------------------------------------------+---------------------+\n",
      "| subtract      | Unrelated concept - mathematical operation |             -0.1055 |\n",
      "+---------------+--------------------------------------------+---------------------+\n",
      "\n",
      "Nearest Neighbors Comparison:\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|   Rank | Cosine Neighbor   |   Cosine Sim | Dot Product Neighbor   |   Dot Score |\n",
      "+========+===================+==============+========================+=============+\n",
      "|      1 | elephant          |       1      | elephant               |     25.054  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      2 | elephants         |       0.7785 | deer                   |     20.9289 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      3 | rhinoceros        |       0.6991 | elephants              |     20.8053 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      4 | rhino             |       0.6805 | rhinoceros             |     18.8669 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      5 | lion              |       0.6701 | animals                |     18.513  |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      6 | deer              |       0.6537 | birds                  |     18.4847 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      7 | boar              |       0.6475 | lion                   |     18.3332 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      8 | monkey            |       0.6435 | animal                 |     18.1964 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|      9 | animal            |       0.6379 | sheep                  |     17.9186 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "|     10 | cat               |       0.6373 | tusks                  |     17.7716 |\n",
      "+--------+-------------------+--------------+------------------------+-------------+\n",
      "\n",
      "Metric Comparison:\n",
      "Common words between metrics: 6 out of 10\n",
      "Significant ranking differences:\n",
      "'deer': Cosine rank 6, Dot rank 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_glove_embeddings(path):\n",
    "    \"\"\"\n",
    "    Loads pre-trained GloVe word embeddings from a text file.\n",
    "    \"\"\"\n",
    "    print(\"Loading GloVe embeddings...\")\n",
    "    word_to_vec = {}\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, total=total_lines):\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_to_vec[word] = vector\n",
    "\n",
    "    embedding_dim = len(next(iter(word_to_vec.values())))\n",
    "    print(f\"Loaded {len(word_to_vec)} words with dimension {embedding_dim}\")\n",
    "    return word_to_vec, embedding_dim\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between two vectors from scratch.\n",
    "    \"\"\"\n",
    "    dot_product = np.sum(vec1 * vec2)\n",
    "    norm1 = np.sqrt(np.sum(vec1 * vec1))\n",
    "    norm2 = np.sqrt(np.sum(vec2 * vec2))\n",
    "\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "def analyze_semantic_similarities(word_to_vec):\n",
    "    \"\"\"\n",
    "    Analyzes semantic similarities between carefully selected word pairs.\n",
    "    Returns results and linguistic judgments.\n",
    "    \"\"\"\n",
    "    word_pairs = {\n",
    "        'computer': {\n",
    "            'laptop': 'Very similar - same category of computing device',\n",
    "            'keyboard': 'Highly related - essential peripheral component',\n",
    "            'software': 'Related - necessary non-physical component',\n",
    "            'desk': 'Contextually related - common location',\n",
    "            'banana': 'Unrelated - different domain (food)',\n",
    "            'sadness': 'Abstract and unrelated - emotion concept'\n",
    "        },\n",
    "        'biology': {\n",
    "            'science': 'Parent category - field of study',\n",
    "            'chemistry': 'Similar field - related natural science',\n",
    "            'microscope': 'Related tool - common instrument',\n",
    "            'research': 'Related activity - general academic concept',\n",
    "            'poetry': 'Unrelated field - arts domain',\n",
    "            'bicycle': 'Unrelated object - transportation domain'\n",
    "        },\n",
    "        'dancing': {\n",
    "            'spinning': 'Very similar action - core movement',\n",
    "            'jumping': 'Related movement - common component',\n",
    "            'music': 'Related context - accompanying element',\n",
    "            'exercise': 'Related concept - physical activity',\n",
    "            'algebra': 'Unrelated concept - mathematics domain',\n",
    "            'pencil': 'Unrelated object - writing tool'\n",
    "        },\n",
    "        'beautiful': {\n",
    "            'gorgeous': 'Synonym - same meaning',\n",
    "            'elegant': 'Similar concept - positive aesthetic',\n",
    "            'attractive': 'Related concept - positive appearance',\n",
    "            'rainbow': 'Associated object - aesthetic phenomenon',\n",
    "            'calculate': 'Unrelated action - mathematical operation',\n",
    "            'wrench': 'Unrelated object - tool'\n",
    "        },\n",
    "        'elephant': {\n",
    "            'giraffe': 'Similar category - large mammal',\n",
    "            'trunk': 'Part-whole relation - body part',\n",
    "            'safari': 'Related context - habitat/viewing',\n",
    "            'zoo': 'Related location - common environment',\n",
    "            'calculator': 'Unrelated object - electronic device',\n",
    "            'subtract': 'Unrelated concept - mathematical operation'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for source_word, target_dict in word_pairs.items():\n",
    "        if source_word not in word_to_vec:\n",
    "            print(f\"Warning: '{source_word}' not found in vocabulary\")\n",
    "            continue\n",
    "\n",
    "        source_vec = word_to_vec[source_word]\n",
    "        word_results = []\n",
    "\n",
    "        for target_word, judgment in target_dict.items():\n",
    "            if target_word not in word_to_vec:\n",
    "                print(f\"Warning: '{target_word}' not found in vocabulary\")\n",
    "                continue\n",
    "\n",
    "            similarity = cosine_similarity(source_vec, word_to_vec[target_word])\n",
    "            word_results.append({\n",
    "                'target_word': target_word,\n",
    "                'judgment': judgment,\n",
    "                'similarity': similarity\n",
    "            })\n",
    "\n",
    "        results[source_word] = word_results\n",
    "\n",
    "    return results\n",
    "\n",
    "def find_nearest_neighbors(source_vec, word_to_vec, k=10, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Efficiently finds k nearest neighbors using matrix operations.\n",
    "    \"\"\"\n",
    "    words = list(word_to_vec.keys())\n",
    "    vectors = np.stack(list(word_to_vec.values()))\n",
    "\n",
    "    if metric == 'cosine':\n",
    "        source_norm = np.linalg.norm(source_vec)\n",
    "        source_vec_norm = source_vec / source_norm\n",
    "        vector_norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "        vectors_norm = vectors / vector_norms\n",
    "        similarities = np.dot(vectors_norm, source_vec_norm)\n",
    "    else:\n",
    "        similarities = np.dot(vectors, source_vec)\n",
    "\n",
    "    top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    return [(words[i], similarities[i]) for i in top_k_indices]\n",
    "\n",
    "\n",
    "# Load embeddings\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "word_to_vec, embedding_dim = load_glove_embeddings(glove_path)\n",
    "\n",
    "# Analyze word similarities\n",
    "print(\"\\n=== Word-to-Word Similarity Analysis ===\")\n",
    "similarity_results = analyze_semantic_similarities(word_to_vec)\n",
    "\n",
    "for source_word, results in similarity_results.items():\n",
    "    print(f\"\\nAnalysis for source word: '{source_word}'\")\n",
    "\n",
    "    # Sort results by similarity score\n",
    "    sorted_results = sorted(results, key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    # Create table\n",
    "    table_data = [[r['target_word'], r['judgment'], f\"{r['similarity']:.4f}\"]\n",
    "                 for r in sorted_results]\n",
    "\n",
    "    print(tabulate(table_data,\n",
    "                  headers=[\"Target Word\", \"Linguistic Judgment\", \"Cosine Similarity\"],\n",
    "                  tablefmt=\"grid\"))\n",
    "\n",
    "    # Find and compare nearest neighbors\n",
    "    source_vec = word_to_vec[source_word]\n",
    "    print(\"\\nNearest Neighbors Comparison:\")\n",
    "    cosine_neighbors = find_nearest_neighbors(source_vec, word_to_vec, k=10, metric='cosine')\n",
    "    dot_neighbors = find_nearest_neighbors(source_vec, word_to_vec, k=10, metric='dot')\n",
    "\n",
    "    comparison_data = []\n",
    "    for i in range(10):\n",
    "        comparison_data.append([\n",
    "            i+1,\n",
    "            cosine_neighbors[i][0],\n",
    "            f\"{cosine_neighbors[i][1]:.4f}\",\n",
    "            dot_neighbors[i][0],\n",
    "            f\"{dot_neighbors[i][1]:.4f}\"\n",
    "        ])\n",
    "\n",
    "    print(tabulate(comparison_data,\n",
    "                  headers=[\"Rank\", \"Cosine Neighbor\", \"Cosine Sim\",\n",
    "                          \"Dot Product Neighbor\", \"Dot Score\"],\n",
    "                  tablefmt=\"grid\"))\n",
    "\n",
    "    # Compare metrics\n",
    "    cosine_words = set(word for word, _ in cosine_neighbors)\n",
    "    dot_words = set(word for word, _ in dot_neighbors)\n",
    "    common_words = cosine_words.intersection(dot_words)\n",
    "\n",
    "    print(\"\\nMetric Comparison:\")\n",
    "    print(f\"Common words between metrics: {len(common_words)} out of 10\")\n",
    "    print(\"Significant ranking differences:\")\n",
    "    for word in common_words:\n",
    "        cosine_rank = [i for i, (w, _) in enumerate(cosine_neighbors) if w == word][0] + 1\n",
    "        dot_rank = [i for i, (w, _) in enumerate(dot_neighbors) if w == word][0] + 1\n",
    "        if abs(cosine_rank - dot_rank) > 3:\n",
    "            print(f\"'{word}': Cosine rank {cosine_rank}, Dot rank {dot_rank}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hUje4Zh0hNa"
   },
   "source": [
    "<h1>Word-to-Word Similarities Analysis:</h1>\n",
    "<ol>\n",
    "<li>\n",
    "For 'computer':\n",
    "The cosine similarities align well with intuitive semantic relationships. Software shows the highest similarity (0.8373), which is interesting as it's not physically equivalent but functionally essential to computers. The progression from laptop (0.7024) to keyboard (0.5418) to desk (0.3806) shows how the similarity decreases as we move from direct equivalents to contextually related items. The very low similarities for banana (0.1213) and sadness (0.0277) confirm that the embeddings effectively capture semantic distance.\n",
    "</li>\n",
    "<li>\n",
    "For 'biology':\n",
    "The embeddings demonstrate strong domain awareness, with chemistry (0.8058) and science (0.7383) showing high similarities. Interestingly, microscope (0.2468) has a lower similarity than expected, suggesting that the embeddings might prioritize conceptual relationships over tool-based associations. The near-zero similarity with bicycle (0.0007) shows appropriate distinction between unrelated domains.\n",
    "</li>\n",
    "<li>\n",
    "For 'dancing':\n",
    "The results reveal an interesting pattern where contextual associations (music: 0.5824) score slightly higher than direct movement similarities (spinning: 0.3994). This suggests the embeddings capture not just physical similarities but broader contextual relationships. The low similarities for pencil (0.1389) and algebra (0.0699) appropriately reflect semantic distance.\n",
    "</li>\n",
    "<li>\n",
    "For 'beautiful':\n",
    "The embeddings show excellent capture of synonyms and related concepts, with gorgeous scoring highest (0.8722) and elegant following (0.7176). Notably, wrench shows a slightly negative similarity (-0.0099), suggesting the embeddings can represent conceptual opposites in terms of aesthetic qualities.\n",
    "</li>\n",
    "<li>For 'elephant':\n",
    "The similarities follow a logical progression from other large mammals (giraffe: 0.6181) to environmental contexts (zoo: 0.5342, safari: 0.4972) to body parts (trunk: 0.3398). The negative similarity with subtract (-0.1055) shows strong domain separation.\n",
    "</li>\n",
    "</ol>\n",
    "<h1>Comparing Similarity Metrics:</h1>\n",
    "The comparison between cosine similarity and dot product reveals several interesting patterns:\n",
    "\n",
    "<h2>Consistency at Extremes:</h2>\n",
    "Both metrics consistently identify the same words as most similar (often the word itself and close variants) and least similar, suggesting robustness in identifying strong semantic relationships.\n",
    "Mid-range Variations: The metrics show more disagreement in middle rankings, with significant rank differences observed for words like:\n",
    "\n",
    "'pc': Cosine rank 5 vs Dot rank 9 for 'computer'\n",
    "'science': Cosine rank 10 vs Dot rank 5 for 'biology'\n",
    "'charming': Cosine rank 5 vs Dot rank 10 for 'beautiful'\n",
    "'deer': Cosine rank 6 vs Dot rank 2 for 'elephant'\n",
    "\n",
    "\n",
    "<h2>Overlap Analysis:</h2>\n",
    "The metrics typically share 6-8 words out of 10 in their top results, suggesting substantial but not complete agreement. This indicates that each metric captures slightly different aspects of semantic similarity.\n",
    "\n",
    "<h2>Metric Preference:</h2>\n",
    "Based on these results, cosine similarity appears to be the more reliable metric for semantic analysis because:\n",
    "\n",
    "It normalizes for vector magnitude, focusing on directional similarity rather than absolute values\n",
    "Its rankings better align with intuitive semantic relationships\n",
    "It provides more consistent results across different word types and domains\n",
    "The similarity scores are easier to interpret as they are bounded between -1 and 1\n",
    "\n",
    "The GloVe embeddings demonstrate remarkable capability in capturing semantic relationships, from direct synonyms to contextual associations, while maintaining clear distinctions between unrelated concepts. This makes them valuable for various natural language processing tasks requiring semantic understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-sHwXjQ0hNa"
   },
   "source": [
    "<a name=\"section-taskB\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Document Classification with WE (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gp3ExtO0hNa"
   },
   "source": [
    "\n",
    "This task follows the same instruction for document classification as provided in Assignment 1. You are indeed free to reuse any part of your code in Assignment 1 for this task. In Assignment 1, the representation of each document was created using a bag of words representation followed by dimensionality reduction. In this task, the document representations are created from the pre-trained word embeddings.\n",
    "\n",
    "**Map word embeddings to dictionary words (5 points).** For every word in the dictionary (as discussed and created in Assignment 1), fetch the corresponding word embedding from the pre-trained model. If no embedding is found, initialize the corresponding word embedding randomly.\n",
    "\n",
    "**Document embedding as the average of word embeddings (5 points).** Using the word embeddings, the representation of each document is defined as the *mean of the vectors of each document's words*. In particular, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
    "\n",
    "$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$\n",
    "\n",
    "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document.\n",
    "\n",
    "**Classification and evaluation (5 points)** Using these new document representations, apply <ins>three classification algorithms</ins> and report the evaluation results (based on accuracy metric) on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T05:19:51.131874Z",
     "start_time": "2024-12-06T05:19:46.174455Z"
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1733457034839,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "OCfe8mbS0hNb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahsan/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/backends/mps/__init__.py:22: UserWarning: Skipping device NVIDIA GeForce GT 750M that does not support Metal 2.0 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSDevice.mm:101.)\n",
      "  return torch._C._mps_is_available()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T05:19:51.144270Z",
     "start_time": "2024-12-06T05:19:51.143028Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3055,
     "status": "ok",
     "timestamp": 1733457038290,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "zedMqPbc08kz",
    "outputId": "7fa8e6fa-5f71-499b-9738-8ad67cecdb4c"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgFlKzNMEch2"
   },
   "source": [
    "### Map word embeddings to dictionary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T05:19:51.148411Z",
     "start_time": "2024-12-06T05:19:51.147043Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733457038290,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "uUh5c61G0hNb"
   },
   "outputs": [],
   "source": [
    "# Load the Datasets\n",
    "trainData = pd.read_csv(\"thedeep.subset.train.txt\", delimiter=\",\", names=['sentence_id', 'text', 'label'])\n",
    "valData = pd.read_csv(\"thedeep.subset.validation.txt\", delimiter=\",\", names=['sentence_id', 'text', 'label'])\n",
    "testData = pd.read_csv(\"thedeep.subset.test.txt\", delimiter=\",\", names=['sentence_id', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T05:19:51.152194Z",
     "start_time": "2024-12-06T05:19:51.151538Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1733457038518,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "tfPL_KBp0hNb",
    "outputId": "d8114d9d-5e5b-4362-9270-76e3a6d2e7e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5446</td>\n",
       "      <td>In addition to the immediate life-saving inter...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8812</td>\n",
       "      <td>There are approximately 2.6 million people cla...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16709</td>\n",
       "      <td>While aid imports have held up recently, comme...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3526</td>\n",
       "      <td>Heavy rainfalls as well as onrush of water fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4928</td>\n",
       "      <td>Based on field reports 9 , the main production...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                               text  label\n",
       "0         5446  In addition to the immediate life-saving inter...      9\n",
       "1         8812  There are approximately 2.6 million people cla...      3\n",
       "2        16709  While aid imports have held up recently, comme...      5\n",
       "3         3526  Heavy rainfalls as well as onrush of water fro...      0\n",
       "4         4928  Based on field reports 9 , the main production...      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733457038518,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "RFbwzyN40hNb",
    "outputId": "94e8c217-4c36-4318-a11a-2e49da12d655"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633</td>\n",
       "      <td>The veterans threw up roadblocks on the main n...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6001</td>\n",
       "      <td>Water department complains about lack of skill...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14014</td>\n",
       "      <td>On 13 February 2018, the Ministry of Health of...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12225</td>\n",
       "      <td>In Kakuma and Kalobeyei, both host and refugee...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10181</td>\n",
       "      <td>'Raqqa is now empty of civilians who had been ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                               text  label\n",
       "0          633  The veterans threw up roadblocks on the main n...      9\n",
       "1         6001  Water department complains about lack of skill...     11\n",
       "2        14014  On 13 February 2018, the Ministry of Health of...      4\n",
       "3        12225  In Kakuma and Kalobeyei, both host and refugee...      7\n",
       "4        10181  'Raqqa is now empty of civilians who had been ...      9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1733457038756,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "vpUH3SvY0hNb"
   },
   "outputs": [],
   "source": [
    "# drop ID sentence\n",
    "trainData = trainData.drop(['sentence_id'], axis=1)\n",
    "valData = valData.drop(['sentence_id'], axis=1)\n",
    "testData = testData.drop(['sentence_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733457038756,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "yziSFCuy0hNb",
    "outputId": "aad16c60-bcaf-4322-a0f5-2fb1bedb58cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In addition to the immediate life-saving inter...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are approximately 2.6 million people cla...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While aid imports have held up recently, comme...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy rainfalls as well as onrush of water fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on field reports 9 , the main production...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  In addition to the immediate life-saving inter...      9\n",
       "1  There are approximately 2.6 million people cla...      3\n",
       "2  While aid imports have held up recently, comme...      5\n",
       "3  Heavy rainfalls as well as onrush of water fro...      0\n",
       "4  Based on field reports 9 , the main production...      3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the new Head of train data to see results\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 362567,
     "status": "ok",
     "timestamp": 1733457401318,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "mDLUSsfu0hNc"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def pp_text(text):\n",
    "    #lower casing, removing puncation and numbers\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    #Tokenize and remove stopwords\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "    #stemming\n",
    "    stemTokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return stemTokens\n",
    "\n",
    "#apply preprocessing\n",
    "trainData['clean_text'] = trainData['text'].apply(pp_text)\n",
    "valData['clean_text'] = valData['text'].apply(pp_text)\n",
    "testData['clean_text'] = testData['text'].apply(pp_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1733457401319,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "QZw5My1H1hW5",
    "outputId": "70451879-dda3-406e-bdd3-305f7413a27d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial sentence was= Overall 30% decrease in MAM Children admissions from 12,879 in April 2016 to 9,047 in April 2017\n",
      "The cleaned sentence is= ['overal', ' ', 'decreas', 'mam', 'children', 'admiss', ' ', 'april', ' ', ' ', 'april']\n"
     ]
    }
   ],
   "source": [
    "print(f'The initial sentence was=', testData['text'][0])\n",
    "print(f'The cleaned sentence is=', testData['clean_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733457401320,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "BjZEwlll1hZq"
   },
   "outputs": [],
   "source": [
    "def clean(tokens):\n",
    "    return [token for token in tokens if token.strip()]\n",
    "\n",
    "trainData['clean_text'] = trainData['clean_text'].apply(clean)\n",
    "valData['clean_text'] = valData['clean_text'].apply(clean)\n",
    "testData['clean_text'] = testData['clean_text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733457401320,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "7wJdX2tT1hcK",
    "outputId": "eee0fbaa-503c-4e6c-b29f-7b0b6d9aadb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned data from trainData:\n",
      "0    [addit, immedi, lifesav, intervent, unicef, ta...\n",
      "1    [approxim, million, peopl, classifi, phase, mi...\n",
      "Name: clean_text, dtype: object\n",
      "\n",
      "Sample cleaned data from valData:\n",
      "0    [veteran, threw, roadblock, main, northbound, ...\n",
      "1    [water, depart, complain, lack, skill, worker,...\n",
      "Name: clean_text, dtype: object\n",
      "\n",
      "Sample cleaned data from testData:\n",
      "0    [overal, decreas, mam, children, admiss, april...\n",
      "1    [fear, ebola, led, attack, health, worker, apr...\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Now lets see if that worked out\n",
    "print(\"Sample cleaned data from trainData:\")\n",
    "print(trainData['clean_text'].head(2))\n",
    "print(\"\\nSample cleaned data from valData:\")\n",
    "print(valData['clean_text'].head(2))\n",
    "print(\"\\nSample cleaned data from testData:\")\n",
    "print(testData['clean_text'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733457401577,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "OVtttoeT5axZ",
    "outputId": "74f74fde-608c-4507-8878-de2074fbd890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial vocabulary size: 23270\n",
      "Top 10 most frequent tokens: [('case', 5594), ('report', 5113), ('food', 4262), ('peopl', 3881), ('area', 3524), ('children', 2953), ('water', 2557), ('health', 2477), ('increas', 2258), ('includ', 2220)]\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(int)\n",
    "for tokens in trainData['clean_text']:\n",
    "    for word in tokens:\n",
    "        vocab[word] += 1\n",
    "\n",
    "#Check the initial vocabulary size and display some sample tokens\n",
    "initial_vocab_size = len(vocab)\n",
    "print(f\"Initial vocabulary size: {initial_vocab_size}\")\n",
    "print(\"Top 10 most frequent tokens:\", sorted(vocab.items(), key=lambda x: x[1], reverse=True)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733457401577,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "eUSqMmGA1he4",
    "outputId": "5ded501a-641e-42f1-b65c-2b73e9b4832d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence is: In 2014, fear of Ebola also led to attacks on health workers. In April 2014, an angry crowd attacked an Ebola treatment center in Macenta, 425 kilometers southeast of Guinea’s capital, Conakry, run by Doctors Without Borders (Medecins Sans Frontieres or MSF), which it accused of bringing Ebola to the city. In August 2014, people in N’Zérékoré, Guinea’s second largest city, protested spraying a market with disinfectant that they believed was infected with the Ebola virus and rioted, injuring over 50 people, including security forces. Law enforcement agencies in Congo should ensure that they can quickly, adequately, and appropriately respond if similar attacks occur.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The tokens of the sentence are: ['fear', 'ebola', 'led', 'attack', 'health', 'worker', 'april', 'angri', 'crowd', 'attack', 'ebola', 'treatment', 'center', 'macenta', 'kilomet', 'southeast', 'guinea', 'capit', 'conakri', 'run', 'doctor', 'border', 'medecin', 'san', 'frontier', 'msf', 'accus', 'bring', 'ebola', 'citi', 'august', 'peopl', 'nzérékoré', 'guinea', 'second', 'largest', 'citi', 'protest', 'spray', 'market', 'disinfect', 'believ', 'infect', 'ebola', 'viru', 'riot', 'injur', 'peopl', 'includ', 'secur', 'forc', 'law', 'enforc', 'agenc', 'congo', 'ensur', 'quickli', 'adequ', 'appropri', 'respond', 'similar', 'attack', 'occur']\n"
     ]
    }
   ],
   "source": [
    "sample_index = 1\n",
    "print(f\"Sample sentence is: {testData['text'][sample_index]}\")\n",
    "print('-------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "#print the tokens of the sentence after preprocessing, vocabulary reduction, and OOV handling\n",
    "print(f\"The tokens of the sentence are: {testData['clean_text'][sample_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733457401577,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "Pg_wNJkX1hht",
    "outputId": "dd0cfd42-d9c8-48e6-f84b-0bb6be786575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial vocabulary size: 23270\n",
      "Reduced vocabulary size after applying frequency threshold: 11198\n"
     ]
    }
   ],
   "source": [
    "#frequency threshold to filter tokens\n",
    "freqThreshold = 1\n",
    "vocabReduced = {token for token, freq in vocab.items() if freq > freqThreshold}\n",
    "\n",
    "initial_vocab_size = len(vocab)\n",
    "reduced_vocab_size = len(vocabReduced)\n",
    "print(f\"Initial vocabulary size: {initial_vocab_size}\")\n",
    "print(f\"Reduced vocabulary size after applying frequency threshold: {reduced_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1733457402379,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "w5XPkGPD1hkJ",
    "outputId": "edeb1c76-caf8-4108-bd2e-66baadc14a14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: In 2014, fear of Ebola also led to attacks on health workers. In April 2014, an angry crowd attacked an Ebola treatment center in Macenta, 425 kilometers southeast of Guinea’s capital, Conakry, run by Doctors Without Borders (Medecins Sans Frontieres or MSF), which it accused of bringing Ebola to the city. In August 2014, people in N’Zérékoré, Guinea’s second largest city, protested spraying a market with disinfectant that they believed was infected with the Ebola virus and rioted, injuring over 50 people, including security forces. Law enforcement agencies in Congo should ensure that they can quickly, adequately, and appropriately respond if similar attacks occur.\n",
      "Tokens after preprocessing and OOV handling: ['fear', 'ebola', 'led', 'attack', 'health', 'worker', 'april', 'angri', 'crowd', 'attack', 'ebola', 'treatment', 'center', '<OOV>', 'kilomet', 'southeast', 'guinea', 'capit', 'conakri', 'run', 'doctor', 'border', 'medecin', 'san', 'frontier', 'msf', 'accus', 'bring', 'ebola', 'citi', 'august', 'peopl', '<OOV>', 'guinea', 'second', 'largest', 'citi', 'protest', 'spray', 'market', 'disinfect', 'believ', 'infect', 'ebola', 'viru', 'riot', 'injur', 'peopl', 'includ', 'secur', 'forc', 'law', 'enforc', 'agenc', 'congo', 'ensur', 'quickli', 'adequ', 'appropri', 'respond', 'similar', 'attack', 'occur']\n"
     ]
    }
   ],
   "source": [
    "#function handle OOV by replacing them with OOV\n",
    "def replace_oov(tokens, vocab):\n",
    "    return [token if token in vocab else \"<OOV>\" for token in tokens]\n",
    "\n",
    "trainData['clean_text'] = trainData['clean_text'].apply(lambda tokens: replace_oov(tokens, vocabReduced))\n",
    "valData['clean_text'] = valData['clean_text'].apply(lambda tokens: replace_oov(tokens, vocabReduced))\n",
    "testData['clean_text'] = testData['clean_text'].apply(lambda tokens: replace_oov(tokens, vocabReduced))\n",
    "\n",
    "sample_index = 1\n",
    "print(f\"Original sentence: {testData['text'][sample_index]}\")\n",
    "print(f\"Tokens after preprocessing and OOV handling: {testData['clean_text'][sample_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15772,
     "status": "ok",
     "timestamp": 1733457418147,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "efJdlVlR1hnC",
    "outputId": "530c3c28-a317-4ef3-f250-8f42b9528796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 400000/400000 [00:08<00:00, 45453.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words with dimension 100\n",
      "Original tokens: ['fear', 'ebola', 'led', 'attack', 'health', 'worker', 'april', 'angri', 'crowd', 'attack', 'ebola', 'treatment', 'center', '<OOV>', 'kilomet', 'southeast', 'guinea', 'capit', 'conakri', 'run', 'doctor', 'border', 'medecin', 'san', 'frontier', 'msf', 'accus', 'bring', 'ebola', 'citi', 'august', 'peopl', '<OOV>', 'guinea', 'second', 'largest', 'citi', 'protest', 'spray', 'market', 'disinfect', 'believ', 'infect', 'ebola', 'viru', 'riot', 'injur', 'peopl', 'includ', 'secur', 'forc', 'law', 'enforc', 'agenc', 'congo', 'ensur', 'quickli', 'adequ', 'appropri', 'respond', 'similar', 'attack', 'occur']\n",
      "Embedding matrix shape: (63, 100)\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(path):\n",
    "    \"\"\"\n",
    "    Loads pre-trained GloVe word embeddings from a text file.\n",
    "    \"\"\"\n",
    "    print(\"Loading GloVe embeddings...\")\n",
    "    word_to_vec = {}\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, total=total_lines):\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_to_vec[word] = vector\n",
    "\n",
    "    embedding_dim = len(next(iter(word_to_vec.values())))\n",
    "    print(f\"Loaded {len(word_to_vec)} words with dimension {embedding_dim}\")\n",
    "    return word_to_vec, embedding_dim\n",
    "\n",
    "# Path to GloVe embeddings\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "\n",
    "# Loading the GloVe embeddings\n",
    "glove_embeddings, embedding_dim = load_glove_embeddings(glove_path)\n",
    "\n",
    "# Creating the word-to-embedding mapping for vocabulary\n",
    "word_embeddings = {}\n",
    "\n",
    "for token in vocabReduced:\n",
    "    if token in glove_embeddings:\n",
    "        word_embeddings[token] = glove_embeddings[token]\n",
    "    else:\n",
    "        # Initializing random embedding for OOV words\n",
    "        word_embeddings[token] = np.random.uniform(-0.01, 0.01, embedding_dim)\n",
    "\n",
    "# Initializing the <OOV> token embedding\n",
    "word_embeddings[\"<OOV>\"] = np.random.uniform(-0.01, 0.01, embedding_dim)\n",
    "\n",
    "# Converting text to embeddings\n",
    "def text_to_embeddings(tokens, word_embeddings, embedding_dim):\n",
    "    \"\"\"\n",
    "    Convert a list of tokens into a matrix of embeddings.\n",
    "    If a token is not found, use the <OOV> embedding.\n",
    "    \"\"\"\n",
    "    return np.array([word_embeddings.get(token, word_embeddings[\"<OOV>\"]) for token in tokens])\n",
    "\n",
    "# Applying to the datasets\n",
    "trainData['embeddings'] = trainData['clean_text'].apply(lambda tokens: text_to_embeddings(tokens, word_embeddings, embedding_dim))\n",
    "valData['embeddings'] = valData['clean_text'].apply(lambda tokens: text_to_embeddings(tokens, word_embeddings, embedding_dim))\n",
    "testData['embeddings'] = testData['clean_text'].apply(lambda tokens: text_to_embeddings(tokens, word_embeddings, embedding_dim))\n",
    "\n",
    "# Check a sample\n",
    "sample_index = 1\n",
    "print(f\"Original tokens: {testData['clean_text'][sample_index]}\")\n",
    "print(f\"Embedding matrix shape: {testData['embeddings'][sample_index].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wfREk5jEReg"
   },
   "source": [
    "### Document embedding as the average of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1655,
     "status": "ok",
     "timestamp": 1733457419798,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "sQqfHyVo1hps",
    "outputId": "a2da12a4-4b84-48fb-eba5-85f0d016f75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tokens: ['fear', 'ebola', 'led', 'attack', 'health', 'worker', 'april', 'angri', 'crowd', 'attack', 'ebola', 'treatment', 'center', '<OOV>', 'kilomet', 'southeast', 'guinea', 'capit', 'conakri', 'run', 'doctor', 'border', 'medecin', 'san', 'frontier', 'msf', 'accus', 'bring', 'ebola', 'citi', 'august', 'peopl', '<OOV>', 'guinea', 'second', 'largest', 'citi', 'protest', 'spray', 'market', 'disinfect', 'believ', 'infect', 'ebola', 'viru', 'riot', 'injur', 'peopl', 'includ', 'secur', 'forc', 'law', 'enforc', 'agenc', 'congo', 'ensur', 'quickli', 'adequ', 'appropri', 'respond', 'similar', 'attack', 'occur']\n",
      "Document embedding (shape): (100,)\n"
     ]
    }
   ],
   "source": [
    "def document_to_embedding(tokens, word_embeddings):\n",
    "    \"\"\"\n",
    "    Compute the document embedding as the average of word embeddings.\n",
    "    If a word is not found in the word_embeddings, use the <OOV> embedding.\n",
    "    \"\"\"\n",
    "    # Fetch embeddings for each token in the document\n",
    "    embeddings = [word_embeddings.get(token, word_embeddings[\"<OOV>\"]) for token in tokens]\n",
    "\n",
    "    # Compute the average embedding by taking the mean of all word embeddings\n",
    "    if embeddings:\n",
    "        doc_embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        # If document is empty (e.g., after cleaning), return a zero vector\n",
    "        doc_embedding = np.zeros_like(next(iter(word_embeddings.values())))\n",
    "\n",
    "    return doc_embedding\n",
    "\n",
    "# Apply the function to your datasets to create document embeddings\n",
    "trainData['doc_embedding'] = trainData['clean_text'].apply(lambda tokens: document_to_embedding(tokens, word_embeddings))\n",
    "valData['doc_embedding'] = valData['clean_text'].apply(lambda tokens: document_to_embedding(tokens, word_embeddings))\n",
    "testData['doc_embedding'] = testData['clean_text'].apply(lambda tokens: document_to_embedding(tokens, word_embeddings))\n",
    "\n",
    "# Check a sample\n",
    "sample_index = 1\n",
    "print(f\"Original tokens: {testData['clean_text'][sample_index]}\")\n",
    "print(f\"Document embedding (shape): {testData['doc_embedding'][sample_index].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh7cQ08tE_fB"
   },
   "source": [
    "### Classification and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35224,
     "status": "ok",
     "timestamp": 1733457455019,
     "user": {
      "displayName": "Bayram Kuliev",
      "userId": "08946045171750565138"
     },
     "user_tz": -60
    },
    "id": "9-j-k9vI1hvQ",
    "outputId": "5f074678-ae92-4413-d957-d231ac3c60c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 74.14%\n",
      "Random Forest accuracy: 68.86%\n",
      "SVM accuracy: 74.68%\n"
     ]
    }
   ],
   "source": [
    "# Assuming the 'doc_embedding' is already computed in the DataFrame\n",
    "\n",
    "# Extracting the embeddings and labels\n",
    "X_train = np.array(trainData['doc_embedding'].tolist())  # Document embeddings for training\n",
    "y_train = trainData['label']  # Corresponding labels for training\n",
    "X_test = np.array(testData['doc_embedding'].tolist())  # Document embeddings for testing\n",
    "y_test = testData['label']  # Corresponding labels for testing\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000)  # Logistic Regression model\n",
    "logreg.fit(X_train, y_train)  # Train the model\n",
    "logreg_pred = logreg.predict(X_test)  # Predict on test set\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_pred)  # Evaluate accuracy\n",
    "\n",
    "# Train and evaluate Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100)  # Random Forest model\n",
    "rf.fit(X_train, y_train)  # Train the model\n",
    "rf_pred = rf.predict(X_test)  # Predict on test set\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)  # Evaluate accuracy\n",
    "\n",
    "# Train and evaluate Support Vector Machine (SVM)\n",
    "svm = SVC()  # SVM model\n",
    "svm.fit(X_train, y_train)  # Train the model\n",
    "svm_pred = svm.predict(X_test)  # Predict on test set\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)  # Evaluate accuracy\n",
    "\n",
    "print(f\"Logistic Regression accuracy: {logreg_accuracy * 100:.2f}%\")\n",
    "print(f\"Random Forest accuracy: {rf_accuracy * 100:.2f}%\")\n",
    "print(f\"SVM accuracy: {svm_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Performing Model:\n",
    "- SVM achieved the highest accuracy at 74.64%, suggesting it is well-suited for this task. This could be attributed to SVM's ability to find the optimal hyperplane in high-dimensional spaces, making it effective for the dense document embeddings generated.\n",
    "\n",
    "Logistic Regression:\n",
    "- Logistic Regression performed rather decently, achieving 74.10%  accuracy. This is a strong baseline model and shows that the document embeddings provide enough information for a linear model to classify effectively.\n",
    "\n",
    "Random Forest:\n",
    "- Random Forest achieved 68.59%, which is lower than the other two models. This is likely because Random Forests may struggle with high-dimensional dense features like those generated by averaging embeddings. Nevertheless the accuracy is still quite high!.#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpwb56F60hNc"
   },
   "source": [
    "<a name=\"section-taskC\"></a><h2 style=\"color:rgb(0,120,170)\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni0d6qbs0hNc"
   },
   "source": [
    "\n",
    "Sent2vec [1] suggests another unsupervised approach to creating document embeddings from the underlying word embeddings. First, using the provided code in the paper, train a sendtvec model on the training set to create document embeddings. Then, repeat Task B while using the document embeddings provided by sent2vec. Similar to Task 2, conduct the classification experiments and report evaluation results.\n",
    "\n",
    "[1] M. Pagliardini, P. Gupta, and M. Jaggi. Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features. In Proceedings of the conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loading Word2Vec model...\n",
      "[=================---------------------------------] 34.8% 578.5/1662.8MB downloaded"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim import downloader as api\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', str(text)).lower()\n",
    "\n",
    "# Load and preprocess data\n",
    "print(\"Loading and preprocessing data...\")\n",
    "train_data = pd.read_csv(\"thedeep.subset.train.txt\", \n",
    "                        delimiter=\",\", \n",
    "                        names=['sentence_id', 'text', 'label'])\n",
    "validation_data = pd.read_csv(\"thedeep.subset.validation.txt\", \n",
    "                            delimiter=\",\", \n",
    "                            names=['sentence_id', 'text', 'label'])\n",
    "test_data = pd.read_csv(\"thedeep.subset.test.txt\", \n",
    "                       delimiter=\",\", \n",
    "                       names=['sentence_id', 'text', 'label'])\n",
    "\n",
    "# Preprocess texts\n",
    "train_texts = train_data['text'].apply(preprocess_text).tolist()\n",
    "validation_texts = validation_data['text'].apply(preprocess_text).tolist()\n",
    "test_texts = test_data['text'].apply(preprocess_text).tolist()\n",
    "\n",
    "# Handle labels\n",
    "all_labels = pd.concat([train_data['label'], validation_data['label'], test_data['label']])\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "train_labels = label_encoder.transform(train_data['label'])\n",
    "validation_labels = label_encoder.transform(validation_data['label'])\n",
    "test_labels = label_encoder.transform(test_data['label'])\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "print(\"Loading Word2Vec model...\")\n",
    "start_time = time.time()\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "print(f\"Model loaded in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "def compute_sent2vec_batch(texts, model, batch_size=1000):\n",
    "    \"\"\"Compute document embeddings in batches\"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        batch_embeddings = []\n",
    "        \n",
    "        for text in batch_texts:\n",
    "            words = text.split()\n",
    "            word_vecs = [model[word] for word in words if word in model]\n",
    "            if word_vecs:\n",
    "                batch_embeddings.append(np.mean(word_vecs, axis=0))\n",
    "            else:\n",
    "                batch_embeddings.append(np.zeros(model.vector_size))\n",
    "                \n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    return np.array(all_embeddings)\n",
    "\n",
    "# Compute embeddings\n",
    "print(\"Computing embeddings...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_embeddings = compute_sent2vec_batch(train_texts, model)\n",
    "validation_embeddings = compute_sent2vec_batch(validation_texts, model)\n",
    "test_embeddings = compute_sent2vec_batch(test_texts, model)\n",
    "\n",
    "print(f\"Embeddings computed in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    clf.fit(train_embeddings, train_labels)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Validate\n",
    "    val_predictions = clf.predict(validation_embeddings)\n",
    "    val_report = classification_report(validation_labels, val_predictions)\n",
    "    \n",
    "    # Test\n",
    "    test_predictions = clf.predict(test_embeddings)\n",
    "    test_report = classification_report(test_labels, test_predictions)\n",
    "    \n",
    "    results[name] = {\n",
    "        'training_time': train_time,\n",
    "        'validation_report': val_report,\n",
    "        'test_report': test_report\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Training Time: {train_time:.2f} seconds\")\n",
    "    print(\"\\nValidation Report:\")\n",
    "    print(val_report)\n",
    "    print(\"\\nTest Report:\")\n",
    "    print(test_report)\n",
    "\n",
    "# Compare with Task B results\n",
    "print(\"\\nComparison with Task B results:\")\n",
    "print(\"-----------------------------\")\n",
    "task_b_results = {\n",
    "    'Logistic Regression': 0.7414,\n",
    "    'Random Forest': 0.6855,\n",
    "    'SVM': 0.7457\n",
    "}\n",
    "\n",
    "# Print differences\n",
    "print(\"\\nAccuracy Differences (Task C - Task B):\")\n",
    "for model_name in task_b_results:\n",
    "    test_acc = float(results[model_name]['test_report'].split('\\n')[-2].split()[-2])\n",
    "    diff = test_acc - task_b_results[model_name]\n",
    "    print(f\"{model_name}: {diff*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
